{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b18c481",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\__init__.py:62\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     64\u001b[39m     ArrowDtype,\n\u001b[32m     65\u001b[39m     Int8Dtype,\n\u001b[32m     66\u001b[39m     Int16Dtype,\n\u001b[32m     67\u001b[39m     Int32Dtype,\n\u001b[32m     68\u001b[39m     Int64Dtype,\n\u001b[32m     69\u001b[39m     UInt8Dtype,\n\u001b[32m     70\u001b[39m     UInt16Dtype,\n\u001b[32m     71\u001b[39m     UInt32Dtype,\n\u001b[32m     72\u001b[39m     UInt64Dtype,\n\u001b[32m     73\u001b[39m     Float32Dtype,\n\u001b[32m     74\u001b[39m     Float64Dtype,\n\u001b[32m     75\u001b[39m     CategoricalDtype,\n\u001b[32m     76\u001b[39m     PeriodDtype,\n\u001b[32m     77\u001b[39m     IntervalDtype,\n\u001b[32m     78\u001b[39m     DatetimeTZDtype,\n\u001b[32m     79\u001b[39m     StringDtype,\n\u001b[32m     80\u001b[39m     BooleanDtype,\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     82\u001b[39m     NA,\n\u001b[32m     83\u001b[39m     isna,\n\u001b[32m     84\u001b[39m     isnull,\n\u001b[32m     85\u001b[39m     notna,\n\u001b[32m     86\u001b[39m     notnull,\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     88\u001b[39m     Index,\n\u001b[32m     89\u001b[39m     CategoricalIndex,\n\u001b[32m     90\u001b[39m     RangeIndex,\n\u001b[32m     91\u001b[39m     MultiIndex,\n\u001b[32m     92\u001b[39m     IntervalIndex,\n\u001b[32m     93\u001b[39m     TimedeltaIndex,\n\u001b[32m     94\u001b[39m     DatetimeIndex,\n\u001b[32m     95\u001b[39m     PeriodIndex,\n\u001b[32m     96\u001b[39m     IndexSlice,\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     98\u001b[39m     NaT,\n\u001b[32m     99\u001b[39m     Period,\n\u001b[32m    100\u001b[39m     period_range,\n\u001b[32m    101\u001b[39m     Timedelta,\n\u001b[32m    102\u001b[39m     timedelta_range,\n\u001b[32m    103\u001b[39m     Timestamp,\n\u001b[32m    104\u001b[39m     date_range,\n\u001b[32m    105\u001b[39m     bdate_range,\n\u001b[32m    106\u001b[39m     Interval,\n\u001b[32m    107\u001b[39m     interval_range,\n\u001b[32m    108\u001b[39m     DateOffset,\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    110\u001b[39m     to_numeric,\n\u001b[32m    111\u001b[39m     to_datetime,\n\u001b[32m    112\u001b[39m     to_timedelta,\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    114\u001b[39m     Flags,\n\u001b[32m    115\u001b[39m     Grouper,\n\u001b[32m    116\u001b[39m     factorize,\n\u001b[32m    117\u001b[39m     unique,\n\u001b[32m    118\u001b[39m     value_counts,\n\u001b[32m    119\u001b[39m     NamedAgg,\n\u001b[32m    120\u001b[39m     array,\n\u001b[32m    121\u001b[39m     Categorical,\n\u001b[32m    122\u001b[39m     set_eng_float_format,\n\u001b[32m    123\u001b[39m     Series,\n\u001b[32m    124\u001b[39m     DataFrame,\n\u001b[32m    125\u001b[39m )\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\api.py:47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Flags\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     Grouper,\n\u001b[32m     49\u001b[39m     NamedAgg,\n\u001b[32m     50\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     52\u001b[39m     CategoricalIndex,\n\u001b[32m     53\u001b[39m     DatetimeIndex,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     TimedeltaIndex,\n\u001b[32m     60\u001b[39m )\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     bdate_range,\n\u001b[32m     63\u001b[39m     date_range,\n\u001b[32m     64\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     DataFrameGroupBy,\n\u001b[32m      3\u001b[39m     NamedAgg,\n\u001b[32m      4\u001b[39m     SeriesGroupBy,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GroupBy\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrouper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Grouper\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:68\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     61\u001b[39m     GroupByApply,\n\u001b[32m     62\u001b[39m     maybe_mangle_lambdas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     warn_alias_replacement,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcom\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     70\u001b[39m     base,\n\u001b[32m     71\u001b[39m     ops,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     74\u001b[39m     GroupBy,\n\u001b[32m     75\u001b[39m     GroupByPlot,\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m     _transform_template,\n\u001b[32m     80\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:149\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseFrameAccessor\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    145\u001b[39m     ensure_wrapped_if_datetimelike,\n\u001b[32m    146\u001b[39m     sanitize_array,\n\u001b[32m    147\u001b[39m     sanitize_masked_array,\n\u001b[32m    148\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    150\u001b[39m     NDFrame,\n\u001b[32m    151\u001b[39m     make_doc,\n\u001b[32m    152\u001b[39m )\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_key_length\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    155\u001b[39m     DatetimeIndex,\n\u001b[32m    156\u001b[39m     Index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m     ensure_index_from_sequences,\n\u001b[32m    161\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:152\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    144\u001b[39m     is_hashable,\n\u001b[32m    145\u001b[39m     is_nested_list_like,\n\u001b[32m    146\u001b[39m )\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    148\u001b[39m     isna,\n\u001b[32m    149\u001b[39m     notna,\n\u001b[32m    150\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    153\u001b[39m     algorithms \u001b[38;5;28;01mas\u001b[39;00m algos,\n\u001b[32m    154\u001b[39m     arraylike,\n\u001b[32m    155\u001b[39m     common,\n\u001b[32m    156\u001b[39m     indexing,\n\u001b[32m    157\u001b[39m     missing,\n\u001b[32m    158\u001b[39m     nanops,\n\u001b[32m    159\u001b[39m     sample,\n\u001b[32m    160\u001b[39m )\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_algos\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreplace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m should_use_regex\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtensionArray\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:79\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     70\u001b[39m     array \u001b[38;5;28;01mas\u001b[39;00m pd_array,\n\u001b[32m     71\u001b[39m     extract_array,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     74\u001b[39m     check_array_indexer,\n\u001b[32m     75\u001b[39m     is_list_like_indexer,\n\u001b[32m     76\u001b[39m     is_scalar_indexer,\n\u001b[32m     77\u001b[39m     length_of_indexer,\n\u001b[32m     78\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     80\u001b[39m     Index,\n\u001b[32m     81\u001b[39m     MultiIndex,\n\u001b[32m     82\u001b[39m )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     86\u001b[39m         Hashable,\n\u001b[32m     87\u001b[39m         Sequence,\n\u001b[32m     88\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\api.py:28\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     Index,\n\u001b[32m     22\u001b[39m     _new_Index,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     get_unanimous_names,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcategory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CategoricalIndex\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatetimeIndex\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntervalIndex\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulti\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiIndex\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatetimelike\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatetimeTimedeltaMixin\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m inherit_names\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_time\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hashable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1178\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1140\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1080\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1504\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1476\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1612\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_es = pd.DataFrame()\n",
    "for i in range(1, 12):\n",
    "    df_temp = pd.read_csv(f'ES_part_{i}.csv')\n",
    "    df_es = pd.concat([df_es, df_temp], ignore_index=True)\n",
    "\n",
    "df_surprise = pd.read_csv('US_economic_releases_events.csv')\n",
    "\n",
    "df_surprise.drop(columns=['S', 'Month', 'Surv(A)', 'Surv(H)', 'Surv(L)',], inplace=True)\n",
    "\n",
    "df_surprise.drop(columns=['Flag', 'Country/Region', 'Day', 'C', 'Category','Subcategory', 'Std Dev', 'Period', 'Actual'])\n",
    "\n",
    "# Dropping all rows for which surprise column has NaN or 0 value\n",
    "df_surprise.dropna(subset=['Surprise'], inplace=True)\n",
    "df_surprise = df_surprise[df_surprise['Surprise'] != 0]\n",
    "\n",
    "df_surprise.replace(\"--\", pd.NA, inplace=True)\n",
    "\n",
    "# Redoing dropping all rows for which surprise column has NaN or 0 value\n",
    "df_surprise.dropna(subset=['Surprise'], inplace=True)\n",
    "df_surprise = df_surprise[df_surprise['Surprise'] != 0]\n",
    "\n",
    "# Convert 'Surprise' column to float\n",
    "df_surprise['Surprise'] = pd.to_numeric(df_surprise['Surprise'], errors='coerce')\n",
    "\n",
    "# Again filtering out rows where 'Surprise' is 0 or NaN\n",
    "df_surprise = df_surprise[df_surprise['Surprise'] != 0].dropna(subset=['Surprise'])\n",
    "\n",
    "df_surprise.dropna(subset=['Time'], inplace=True)\n",
    "\n",
    "# Wincorsizing to get results between 0.5% and 99.5% percentile for Surprise values\n",
    "lower_bound = df_surprise['Surprise'].quantile(0.005)\n",
    "upper_bound = df_surprise['Surprise'].quantile(0.995)\n",
    "\n",
    "df_surprise = df_surprise[(df_surprise['Surprise'] >= lower_bound) & (df_surprise['Surprise'] <= upper_bound)]\n",
    "\n",
    "# Step 1: Ensure columns are strings\n",
    "df_surprise['Date'] = df_surprise['Date'].astype(str)\n",
    "df_surprise['Time'] = df_surprise['Time'].astype(str)\n",
    "\n",
    "# Step 2: Handle missing times (if any)\n",
    "df_surprise['Time'] = df_surprise['Time'].fillna('00:00:00')\n",
    "\n",
    "# Step 3: Combine Date and Time into DateTime\n",
    "df_surprise['DateTime'] = pd.to_datetime(\n",
    "    df_surprise['Date'].str[:10] + ' ' + df_surprise['Time'],\n",
    "    format='%Y-%m-%d %H:%M:%S',\n",
    "    errors='coerce'  # Converts invalid parsing to NaT instead of raising error\n",
    ")\n",
    "\n",
    "# First we drop Date and DateTime and change the column name for Unnamed: 0 to Date\n",
    "\n",
    "df_surprise.drop(columns=['Date', 'DateTime'], inplace=True)\n",
    "df_surprise.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n",
    "\n",
    "# Now let's again create a DateTime column with the new Date column and check for number of NaN values\n",
    "# Step 1: Ensure columns are strings\n",
    "df_surprise['Date'] = df_surprise['Date'].astype(str)\n",
    "df_surprise['Time'] = df_surprise['Time'].astype(str)\n",
    "\n",
    "# Step 2: Handle missing times (if any)\n",
    "df_surprise['Time'] = df_surprise['Time'].fillna('00:00:00')\n",
    "\n",
    "# Step 3: Combine Date and Time into DateTime\n",
    "df_surprise['DateTime'] = pd.to_datetime(\n",
    "    df_surprise['Date'].str[:10] + ' ' + df_surprise['Time'],\n",
    "    format='%Y-%m-%d %H:%M:%S',\n",
    "    errors='coerce'  # Converts invalid parsing to NaT instead of raising error\n",
    ")\n",
    "\n",
    "# Step 1: Ensure columns are strings\n",
    "df_es['Date'] = df_es['Date'].astype(str)\n",
    "df_es['Time'] = df_es['Time'].astype(str)\n",
    "\n",
    "# Step 2: Handle missing times (if any) and pad with seconds\n",
    "df_es['Time'] = df_es['Time'].fillna('00:00')  # Fill missing times\n",
    "df_es['Time'] = df_es['Time'] + ':00'  # Add seconds to make HH:MM:SS format\n",
    "\n",
    "# Step 3: Combine Date and Time into DateTime with correct format\n",
    "df_es['DateTime'] = pd.to_datetime(\n",
    "    df_es['Date'] + ' ' + df_es['Time'],\n",
    "    format='%m/%d/%Y %H:%M:%S',  # Matches MM/DD/YYYY date and HH:MM:SS time\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Now we create the merged dataframe for our analysis - to allow us to match times of surprise with the price of the future at the time\n",
    "df_combined = pd.merge(\n",
    "    df_es,\n",
    "    df_surprise,\n",
    "    on='DateTime',\n",
    "    how='outer',\n",
    "    suffixes=('_es', '_surprise'),\n",
    "    indicator=True  # this shows the source of each using suffix\n",
    ")\n",
    "\n",
    "# Some surprise announcements might have come before the starting point for the data on the futures, these would be meaningless for our analysis and should thus\n",
    "# be removed by removing all rows with NaN values for Open\n",
    "\n",
    "df_combined.dropna(subset=['Open'], inplace=True)\n",
    "\n",
    "df_combined['Surprise Occurred'] = df_combined['Surprise'].notna()\n",
    "\n",
    "\n",
    "df_combined['First Post Surprise'] = df_combined['Surprise Occurred'].shift(1)\n",
    "df_combined['First Post Surprise'].iloc[0] = False\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_period = 20\n",
    "transaction_cost = 0.000025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a2a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_es</th>\n",
       "      <th>Time_es</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Date_surprise</th>\n",
       "      <th>Period</th>\n",
       "      <th>Event</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>...</th>\n",
       "      <th>Flag</th>\n",
       "      <th>_merge</th>\n",
       "      <th>Surprise Occurred</th>\n",
       "      <th>First Post Surprise</th>\n",
       "      <th>N_Return</th>\n",
       "      <th>N_Return_half</th>\n",
       "      <th>N_Return_double</th>\n",
       "      <th>Return</th>\n",
       "      <th>Return_half</th>\n",
       "      <th>Return_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:01:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:02:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:04:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695761</th>\n",
       "      <td>12/19/2024</td>\n",
       "      <td>15:56:00</td>\n",
       "      <td>5941.75</td>\n",
       "      <td>5941.75</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2024-12-19 15:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695762</th>\n",
       "      <td>12/19/2024</td>\n",
       "      <td>15:57:00</td>\n",
       "      <td>5941.75</td>\n",
       "      <td>5941.50</td>\n",
       "      <td>386.0</td>\n",
       "      <td>2024-12-19 15:57:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695763</th>\n",
       "      <td>12/19/2024</td>\n",
       "      <td>15:58:00</td>\n",
       "      <td>5941.50</td>\n",
       "      <td>5941.00</td>\n",
       "      <td>484.0</td>\n",
       "      <td>2024-12-19 15:58:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695764</th>\n",
       "      <td>12/19/2024</td>\n",
       "      <td>15:59:00</td>\n",
       "      <td>5940.75</td>\n",
       "      <td>5941.00</td>\n",
       "      <td>6462.0</td>\n",
       "      <td>2024-12-19 15:59:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695765</th>\n",
       "      <td>12/19/2024</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>5941.00</td>\n",
       "      <td>5941.25</td>\n",
       "      <td>8864.0</td>\n",
       "      <td>2024-12-19 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9695665 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date_es   Time_es     Open    Close  Volume            DateTime  \\\n",
       "2        09/10/1997  00:01:00     0.00     0.00     0.0 1997-09-10 00:01:00   \n",
       "3        09/10/1997  00:02:00     0.00     0.00     0.0 1997-09-10 00:02:00   \n",
       "4        09/10/1997  00:03:00     0.00     0.00     0.0 1997-09-10 00:03:00   \n",
       "5        09/10/1997  00:04:00     0.00     0.00     0.0 1997-09-10 00:04:00   \n",
       "6        09/10/1997  00:05:00     0.00     0.00     0.0 1997-09-10 00:05:00   \n",
       "...             ...       ...      ...      ...     ...                 ...   \n",
       "9695761  12/19/2024  15:56:00  5941.75  5941.75   318.0 2024-12-19 15:56:00   \n",
       "9695762  12/19/2024  15:57:00  5941.75  5941.50   386.0 2024-12-19 15:57:00   \n",
       "9695763  12/19/2024  15:58:00  5941.50  5941.00   484.0 2024-12-19 15:58:00   \n",
       "9695764  12/19/2024  15:59:00  5940.75  5941.00  6462.0 2024-12-19 15:59:00   \n",
       "9695765  12/19/2024  16:00:00  5941.00  5941.25  8864.0 2024-12-19 16:00:00   \n",
       "\n",
       "        Date_surprise Period Event Ticker  ... Flag     _merge  \\\n",
       "2                 NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "3                 NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "4                 NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "5                 NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "6                 NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "...               ...    ...   ...    ...  ...  ...        ...   \n",
       "9695761           NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "9695762           NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "9695763           NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "9695764           NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "9695765           NaN    NaN   NaN    NaN  ...  NaN  left_only   \n",
       "\n",
       "        Surprise Occurred First Post Surprise N_Return N_Return_half  \\\n",
       "2                   False               False      NaN           NaN   \n",
       "3                   False               False      NaN           NaN   \n",
       "4                   False               False      NaN           NaN   \n",
       "5                   False               False      NaN           NaN   \n",
       "6                   False               False      NaN           NaN   \n",
       "...                   ...                 ...      ...           ...   \n",
       "9695761             False               False      NaN           NaN   \n",
       "9695762             False               False      NaN           NaN   \n",
       "9695763             False               False      NaN           NaN   \n",
       "9695764             False               False      NaN           NaN   \n",
       "9695765             False               False      NaN           NaN   \n",
       "\n",
       "        N_Return_double Return Return_half  Return_double  \n",
       "2                   NaN    NaN         NaN            NaN  \n",
       "3                   NaN    NaN         NaN            NaN  \n",
       "4                   NaN    NaN         NaN            NaN  \n",
       "5                   NaN    NaN         NaN            NaN  \n",
       "6                   NaN    NaN         NaN            NaN  \n",
       "...                 ...    ...         ...            ...  \n",
       "9695761             NaN    NaN         NaN            NaN  \n",
       "9695762             NaN    NaN         NaN            NaN  \n",
       "9695763             NaN    NaN         NaN            NaN  \n",
       "9695764             NaN    NaN         NaN            NaN  \n",
       "9695765             NaN    NaN         NaN            NaN  \n",
       "\n",
       "[9695665 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['N_Return'] = np.nan\n",
    "df_combined['N_Return_half'] = np.nan\n",
    "df_combined['N_Return_double'] = np.nan\n",
    "df_combined['Return'] = np.nan\n",
    "df_combined['Return_half'] = np.nan\n",
    "df_combined['Return_double'] = np.nan\n",
    "\n",
    "surprise_rows = df_combined[df_combined['First Post Surprise'] == True]\n",
    "\n",
    "for index, row in surprise_rows.iterrows():\n",
    "    row_position = df_combined.index.get_loc(index)\n",
    "\n",
    "    # Get the Surprise value from the previous row\n",
    "    if index > df_combined.index[0]:\n",
    "        prev_surprise = df_combined.at[df_combined.index[df_combined.index.get_loc(index)-1], 'Surprise']\n",
    "    else:\n",
    "        prev_surprise = 0  # Default if no previous row exists\n",
    "\n",
    "    if row_position + holding_period < len(df_combined):\n",
    "        current_price = row['Open']\n",
    "        future_row = df_combined.iloc[row_position + holding_period]\n",
    "        future_price = future_row['Open']\n",
    "\n",
    "        if current_price != 0:\n",
    "            percentage_increase = (future_price - current_price) / current_price\n",
    "        else:\n",
    "            percentage_increase = np.nan\n",
    "\n",
    "        df_combined.at[index, 'Return'] = percentage_increase\n",
    "        if prev_surprise < 0:\n",
    "            df_combined.at[index, 'N_Return'] = -percentage_increase\n",
    "        else:\n",
    "            df_combined.at[index, 'N_Return'] = percentage_increase\n",
    "\n",
    "    if row_position + int(holding_period*0.5) < len(df_combined): # int converts to whole number to avoid that potential error\n",
    "        current_price = row['Open']\n",
    "        future_row = df_combined.iloc[row_position + int(holding_period*0.5)]\n",
    "        future_price = future_row['Open']\n",
    "\n",
    "        if current_price != 0:\n",
    "            percentage_increase = (future_price - current_price) / current_price\n",
    "        else:\n",
    "            percentage_increase = np.nan\n",
    "\n",
    "        df_combined.at[index, 'Return_half'] = percentage_increase\n",
    "        if prev_surprise < 0:\n",
    "            df_combined.at[index, 'N_Return_half'] = -percentage_increase\n",
    "        else:\n",
    "            df_combined.at[index, 'N_Return_half'] = percentage_increase\n",
    "\n",
    "    if row_position + int(holding_period*2) < len(df_combined):\n",
    "        current_price = row['Open']\n",
    "        future_row = df_combined.iloc[row_position + int(holding_period*2)]\n",
    "        future_price = future_row['Open']\n",
    "\n",
    "        if current_price != 0:\n",
    "            percentage_increase = (future_price - current_price) / current_price\n",
    "        else:\n",
    "            percentage_increase = np.nan\n",
    "\n",
    "        df_combined.at[index, 'Return_double'] = percentage_increase\n",
    "        if prev_surprise < 0:\n",
    "            df_combined.at[index, 'N_Return_double'] = -percentage_increase\n",
    "        else:\n",
    "            df_combined.at[index, 'N_Return_double'] = percentage_increase\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b567d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date_es                      0\n",
       "Time_es                      0\n",
       "Open                         0\n",
       "Close                        0\n",
       "Volume                       0\n",
       "DateTime                     0\n",
       "Date_surprise          9672597\n",
       "Period                 9672597\n",
       "Event                  9672597\n",
       "Ticker                 9672597\n",
       "Actual                 9672597\n",
       "Prior                  9672616\n",
       "Revised                9681231\n",
       "Freq.                  9672597\n",
       "First Rev.             9681231\n",
       "Last Rev.              9676757\n",
       "Time_surprise          9672597\n",
       "C                      9672597\n",
       "Category               9672597\n",
       "Subcategory            9695665\n",
       "R                      9672597\n",
       "Day                    9672597\n",
       "Surv(M)                9672597\n",
       "# Ests.                9672597\n",
       "Std Dev                9672597\n",
       "Surprise               9672597\n",
       "Country/Region         9672597\n",
       "Flag                   9672597\n",
       "_merge                       0\n",
       "Surprise Occurred            0\n",
       "First Post Surprise          0\n",
       "N_Return               9672597\n",
       "N_Return_half          9672597\n",
       "N_Return_double        9672597\n",
       "Return                 9672597\n",
       "Return_half            9672597\n",
       "Return_double          9672597\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of NaN values for this new column make sense - same as the number of NaNs for the Surprise column\n",
    "df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9129286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>R</th>\n",
       "      <th># Ests.</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>N_Return</th>\n",
       "      <th>N_Return_half</th>\n",
       "      <th>N_Return_double</th>\n",
       "      <th>Return</th>\n",
       "      <th>Return_half</th>\n",
       "      <th>Return_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.695665e+06</td>\n",
       "      <td>9.695665e+06</td>\n",
       "      <td>9.695665e+06</td>\n",
       "      <td>9695665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23068.000000</td>\n",
       "      <td>23068.000000</td>\n",
       "      <td>23068.000000</td>\n",
       "      <td>23068.000000</td>\n",
       "      <td>23068.000000</td>\n",
       "      <td>23068.000000</td>\n",
       "      <td>23068.000000</td>\n",
       "      <td>23068.000000</td>\n",
       "      <td>23068.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.157033e+03</td>\n",
       "      <td>2.157033e+03</td>\n",
       "      <td>8.646174e+02</td>\n",
       "      <td>2011-04-26 02:54:35.758778112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.220673</td>\n",
       "      <td>37.124155</td>\n",
       "      <td>0.028913</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1997-09-10 00:01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-9.580000</td>\n",
       "      <td>-0.036467</td>\n",
       "      <td>-0.032139</td>\n",
       "      <td>-0.034818</td>\n",
       "      <td>-0.036467</td>\n",
       "      <td>-0.032139</td>\n",
       "      <td>-0.036751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.239050e+03</td>\n",
       "      <td>1.239050e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2004-07-22 03:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.963000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-1.510000</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>-0.001324</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.000784</td>\n",
       "      <td>-0.001328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.501040e+03</td>\n",
       "      <td>1.501040e+03</td>\n",
       "      <td>9.100000e+01</td>\n",
       "      <td>2011-04-08 00:31:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.481500</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.860620e+03</td>\n",
       "      <td>2.860620e+03</td>\n",
       "      <td>6.390000e+02</td>\n",
       "      <td>2018-02-11 18:52:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.666700</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.001357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.181130e+03</td>\n",
       "      <td>6.181130e+03</td>\n",
       "      <td>2.149820e+05</td>\n",
       "      <td>2024-12-19 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.259300</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>0.032054</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>0.036751</td>\n",
       "      <td>0.029750</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.033010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.314762e+03</td>\n",
       "      <td>1.314761e+03</td>\n",
       "      <td>2.242572e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.822984</td>\n",
       "      <td>24.044298</td>\n",
       "      <td>2.551234</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.003553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open         Close        Volume  \\\n",
       "count  9.695665e+06  9.695665e+06  9.695665e+06   \n",
       "mean   2.157033e+03  2.157033e+03  8.646174e+02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.239050e+03  1.239050e+03  0.000000e+00   \n",
       "50%    1.501040e+03  1.501040e+03  9.100000e+01   \n",
       "75%    2.860620e+03  2.860620e+03  6.390000e+02   \n",
       "max    6.181130e+03  6.181130e+03  2.149820e+05   \n",
       "std    1.314762e+03  1.314761e+03  2.242572e+03   \n",
       "\n",
       "                            DateTime  Subcategory             R       # Ests.  \\\n",
       "count                        9695665          0.0  23068.000000  23068.000000   \n",
       "mean   2011-04-26 02:54:35.758778112          NaN     63.220673     37.124155   \n",
       "min              1997-09-10 00:01:00          NaN      0.000000      3.000000   \n",
       "25%              2004-07-22 03:37:00          NaN     42.963000     14.000000   \n",
       "50%              2011-04-08 00:31:00          NaN     69.481500     37.000000   \n",
       "75%              2018-02-11 18:52:00          NaN     86.666700     57.000000   \n",
       "max              2024-12-19 16:00:00          NaN     99.259300    139.000000   \n",
       "std                              NaN          NaN     28.822984     24.044298   \n",
       "\n",
       "           Surprise      N_Return  N_Return_half  N_Return_double  \\\n",
       "count  23068.000000  23068.000000   23068.000000     23068.000000   \n",
       "mean       0.028913      0.000012       0.000016        -0.000005   \n",
       "min       -9.580000     -0.036467      -0.032139        -0.034818   \n",
       "25%       -1.510000     -0.000981      -0.000749        -0.001324   \n",
       "50%       -0.010000      0.000000       0.000000         0.000000   \n",
       "75%        1.530000      0.001062       0.000848         0.001363   \n",
       "max       10.580000      0.032054       0.023758         0.036751   \n",
       "std        2.551234      0.002987       0.002555         0.003553   \n",
       "\n",
       "             Return   Return_half  Return_double  \n",
       "count  23068.000000  23068.000000   23068.000000  \n",
       "mean       0.000003     -0.000012      -0.000008  \n",
       "min       -0.036467     -0.032139      -0.036751  \n",
       "25%       -0.000990     -0.000784      -0.001328  \n",
       "50%        0.000000      0.000000       0.000000  \n",
       "75%        0.001047      0.000822       0.001357  \n",
       "max        0.029750      0.027740       0.033010  \n",
       "std        0.002987      0.002555       0.003553  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7830c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average market open minutes per day: 1147.8\n",
      "Average holding-period intervals per day: 20.0\n"
     ]
    }
   ],
   "source": [
    "# Just checking how long futures market is typically open for (some surprises on same day might bias this value a bit but not by muchh)\n",
    "date_counts = df_combined['DateTime'].dt.floor('D').value_counts()\n",
    "\n",
    "# Calculate statistics\n",
    "avg_minutes_per_day = date_counts.mean()\n",
    "avg_holding_period_intervals = avg_minutes_per_day / holding_period\n",
    "\n",
    "print(f\"Average market open minutes per day: {avg_minutes_per_day:.1f}\")\n",
    "print(f\"Average holding-period intervals per day: {holding_period:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc072981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.253384860842976e-06\n"
     ]
    }
   ],
   "source": [
    "average_return = df_combined['Return'].dropna().mean()\n",
    "print(average_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^GSPC']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\2657130017.py:43: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  economic_data['SP500'] = prices_on_releases.pct_change()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp_gr</th>\n",
       "      <th>NFP</th>\n",
       "      <th>un_rate</th>\n",
       "      <th>cci</th>\n",
       "      <th>ret_sales</th>\n",
       "      <th>IPTI</th>\n",
       "      <th>cpi</th>\n",
       "      <th>TXBPPRIVSA</th>\n",
       "      <th>ffr</th>\n",
       "      <th>SP500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gdp_gr, NFP, un_rate, cci, ret_sales, IPTI, cpi, TXBPPRIVSA, ffr, SP500]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import datetime\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# --- 1. Get GDP Release Dates (Quarterly) ---\n",
    "start = datetime.datetime(1997, 1, 1)\n",
    "end = datetime.datetime.today()\n",
    "gdp_releases = pdr.DataReader('A191RL1Q225SBEA', 'fred', start, end).index\n",
    "\n",
    "# --- 2. Download All Economic Data ---\n",
    "raw_data = {\n",
    "    # Quarterly\n",
    "    'gdp_gr': pdr.DataReader('A191RL1Q225SBEA', 'fred', start, end),\n",
    "\n",
    "    # Monthly\n",
    "    'NFP': pdr.DataReader('PAYEMS', 'fred', start, end),\n",
    "    'un_rate': pdr.DataReader('UNRATE', 'fred', start, end),\n",
    "    'cci': pdr.DataReader('UMCSENT', 'fred', start, end),\n",
    "    'ret_sales': pdr.DataReader('RSAFS', 'fred', start, end),\n",
    "    'IPTI': pdr.DataReader('INDPRO', 'fred', start, end),\n",
    "    'cpi': pdr.DataReader('CPIAUCSL', 'fred', start, end),\n",
    "    'TXBPPRIVSA': pdr.DataReader('TXBPPRIVSA', 'fred', start, end),  # Added this line\n",
    "\n",
    "    # Daily\n",
    "    'ffr': pdr.DataReader('DFF', 'fred', start, end),\n",
    "\n",
    "    # S&P 500 (via yfinance)\n",
    "    'sp500': yf.download('^GSPC', start=start, end=end)['Close']\n",
    "}\n",
    "\n",
    "# --- 3. Align ALL Variables to GDP Release Dates ---\n",
    "economic_data = pd.DataFrame(index=gdp_releases)\n",
    "\n",
    "for name, series in raw_data.items():\n",
    "    if name == 'gdp_gr':\n",
    "        economic_data[name] = series  # Already aligned\n",
    "    elif name == 'sp500':\n",
    "        # Calculate quarterly returns between GDP releases\n",
    "        prices_on_releases = series.reindex(gdp_releases, method='bfill')\n",
    "        economic_data['SP500'] = prices_on_releases.pct_change()\n",
    "    elif name == 'ffr':\n",
    "        # Take FFR value ON the GDP release day\n",
    "        economic_data[name] = series.reindex(gdp_releases, method='bfill')\n",
    "    else:\n",
    "        # Monthly series: last release BEFORE GDP date\n",
    "        economic_data[name] = series.reindex(gdp_releases, method='ffill')\n",
    "\n",
    "# --- 4. Clean and Verify ---\n",
    "economic_data = economic_data.dropna(subset=['gdp_gr'])  # Remove quarters without GDP\n",
    "\n",
    "# remove row where year is 2025\n",
    "economic_data = economic_data[economic_data.index.year != 2025]\n",
    "\n",
    "economic_data = economic_data.dropna()\n",
    "\n",
    "economic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bac350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp_gr</th>\n",
       "      <th>NFP</th>\n",
       "      <th>un_rate</th>\n",
       "      <th>cci</th>\n",
       "      <th>ret_sales</th>\n",
       "      <th>IPTI</th>\n",
       "      <th>cpi</th>\n",
       "      <th>TXBPPRIVSA</th>\n",
       "      <th>ffr</th>\n",
       "      <th>SP500</th>\n",
       "      <th>gdp_gr_L1</th>\n",
       "      <th>ffr_L1</th>\n",
       "      <th>NFP_L1</th>\n",
       "      <th>un_rate_L1</th>\n",
       "      <th>cci_L1</th>\n",
       "      <th>ret_sales_L1</th>\n",
       "      <th>IPTI_L1</th>\n",
       "      <th>cpi_L1</th>\n",
       "      <th>TXBPPRIVSA_L1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gdp_gr, NFP, un_rate, cci, ret_sales, IPTI, cpi, TXBPPRIVSA, ffr, SP500, gdp_gr_L1, ffr_L1, NFP_L1, un_rate_L1, cci_L1, ret_sales_L1, IPTI_L1, cpi_L1, TXBPPRIVSA_L1]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economic_data['gdp_gr_L1'] = economic_data['gdp_gr'].shift(1)\n",
    "economic_data['ffr_L1'] = economic_data['ffr'].shift(1)\n",
    "economic_data['NFP_L1'] = economic_data['NFP'].shift(1)\n",
    "economic_data['un_rate_L1'] = economic_data['un_rate'].shift(1)\n",
    "economic_data['cci_L1'] = economic_data['cci'].shift(1)\n",
    "economic_data['ret_sales_L1'] = economic_data['ret_sales'].shift(1)\n",
    "economic_data['IPTI_L1'] = economic_data['IPTI'].shift(1)\n",
    "economic_data['cpi_L1'] = economic_data['cpi'].shift(1)\n",
    "economic_data['TXBPPRIVSA_L1'] = economic_data['TXBPPRIVSA'].shift(1)\n",
    "\n",
    "economic_data = economic_data.dropna()\n",
    "\n",
    "economic_data.index = pd.to_datetime(economic_data.index)\n",
    "\n",
    "economic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a912abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\2640991562.py:1: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_surprise = pd.read_csv('US_economic_releases_events (3).csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Blomberg indicators</th>\n",
       "      <th>Description</th>\n",
       "      <th>Broad indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VNCCTOT Index</td>\n",
       "      <td>Vehicle Sales Total</td>\n",
       "      <td>Retail sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHUCCHNG Index</td>\n",
       "      <td>Pending Home Sales Change</td>\n",
       "      <td>Building permits - new private housing units a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CICRTOT Index</td>\n",
       "      <td>Construction Spending Total</td>\n",
       "      <td>GDP growth rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MWINCHNG Index</td>\n",
       "      <td>MBA Mortgage Applications Change</td>\n",
       "      <td>Building permits - new private housing units a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFP TCH Index</td>\n",
       "      <td>Nonfarm Payrolls Total Change</td>\n",
       "      <td>Non-farm payrolls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NYCNM1IR Index</td>\n",
       "      <td>NY Fed: Empire State Manufacturing Index</td>\n",
       "      <td>Industrial production</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>DOTDY0MD Index</td>\n",
       "      <td>Department of Transportation: Domestic Air Rev...</td>\n",
       "      <td>GDP growth rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>DOTDY1MD Index</td>\n",
       "      <td>Department of Transportation: International Ai...</td>\n",
       "      <td>GDP growth rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>DOTDY2MD Index</td>\n",
       "      <td>Department of Transportation: Systemwide Air R...</td>\n",
       "      <td>GDP growth rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>DOTDLTMD Index</td>\n",
       "      <td>Department of Transportation: Load Factor</td>\n",
       "      <td>GDP growth rate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    All Blomberg indicators  \\\n",
       "0             VNCCTOT Index   \n",
       "1            PHUCCHNG Index   \n",
       "2             CICRTOT Index   \n",
       "3            MWINCHNG Index   \n",
       "4             NFP TCH Index   \n",
       "..                      ...   \n",
       "156          NYCNM1IR Index   \n",
       "157          DOTDY0MD Index   \n",
       "158          DOTDY1MD Index   \n",
       "159          DOTDY2MD Index   \n",
       "160          DOTDLTMD Index   \n",
       "\n",
       "                                           Description  \\\n",
       "0                                  Vehicle Sales Total   \n",
       "1                            Pending Home Sales Change   \n",
       "2                          Construction Spending Total   \n",
       "3                     MBA Mortgage Applications Change   \n",
       "4                        Nonfarm Payrolls Total Change   \n",
       "..                                                 ...   \n",
       "156           NY Fed: Empire State Manufacturing Index   \n",
       "157  Department of Transportation: Domestic Air Rev...   \n",
       "158  Department of Transportation: International Ai...   \n",
       "159  Department of Transportation: Systemwide Air R...   \n",
       "160          Department of Transportation: Load Factor   \n",
       "\n",
       "                                       Broad indicator  \n",
       "0                                         Retail sales  \n",
       "1    Building permits - new private housing units a...  \n",
       "2                                      GDP growth rate  \n",
       "3    Building permits - new private housing units a...  \n",
       "4                                    Non-farm payrolls  \n",
       "..                                                 ...  \n",
       "156                              Industrial production  \n",
       "157                                    GDP growth rate  \n",
       "158                                    GDP growth rate  \n",
       "159                                    GDP growth rate  \n",
       "160                                    GDP growth rate  \n",
       "\n",
       "[161 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_surprise = pd.read_csv('US_economic_releases_events (3).csv')\n",
    "\n",
    "df_mapping = pd.read_excel('US Variable mapping (1).xlsx')\n",
    "\n",
    "df_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e120e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>Broad indicator</th>\n",
       "      <th>Date_es</th>\n",
       "      <th>Time_es</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Date_surprise</th>\n",
       "      <th>...</th>\n",
       "      <th>Flag</th>\n",
       "      <th>_merge</th>\n",
       "      <th>Surprise Occurred</th>\n",
       "      <th>First Post Surprise</th>\n",
       "      <th>N_Return</th>\n",
       "      <th>N_Return_half</th>\n",
       "      <th>N_Return_double</th>\n",
       "      <th>Return</th>\n",
       "      <th>Return_half</th>\n",
       "      <th>Return_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23088</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23089</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:02:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23090</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23091</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23092</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/10/1997</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-09-10 00:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17882</th>\n",
       "      <td>PHUCCHNG Index</td>\n",
       "      <td>Pending Home Sales Change</td>\n",
       "      <td>Building permits - new private housing units a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19078</th>\n",
       "      <td>RCSSCLBC Index</td>\n",
       "      <td>Retail Sales Control Group</td>\n",
       "      <td>Retail sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>REALYRAW Index</td>\n",
       "      <td>Real Personal Consumption Expenditures</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>REDSMMOM Index</td>\n",
       "      <td>Redbook Same-Store Sales Monthly Change</td>\n",
       "      <td>Retail sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23087</th>\n",
       "      <td>VNCCTOT Index</td>\n",
       "      <td>Vehicle Sales Total</td>\n",
       "      <td>Retail sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9695685 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ticker                              Description  \\\n",
       "23088             NaN                                      NaN   \n",
       "23089             NaN                                      NaN   \n",
       "23090             NaN                                      NaN   \n",
       "23091             NaN                                      NaN   \n",
       "23092             NaN                                      NaN   \n",
       "...               ...                                      ...   \n",
       "17882  PHUCCHNG Index                Pending Home Sales Change   \n",
       "19078  RCSSCLBC Index               Retail Sales Control Group   \n",
       "19096  REALYRAW Index   Real Personal Consumption Expenditures   \n",
       "19097  REDSMMOM Index  Redbook Same-Store Sales Monthly Change   \n",
       "23087   VNCCTOT Index                      Vehicle Sales Total   \n",
       "\n",
       "                                         Broad indicator     Date_es  \\\n",
       "23088                                                NaN  09/10/1997   \n",
       "23089                                                NaN  09/10/1997   \n",
       "23090                                                NaN  09/10/1997   \n",
       "23091                                                NaN  09/10/1997   \n",
       "23092                                                NaN  09/10/1997   \n",
       "...                                                  ...         ...   \n",
       "17882  Building permits - new private housing units a...         NaN   \n",
       "19078                                       Retail sales         NaN   \n",
       "19096                                    GDP growth rate         NaN   \n",
       "19097                                       Retail sales         NaN   \n",
       "23087                                       Retail sales         NaN   \n",
       "\n",
       "        Time_es  Open  Close  Volume            DateTime Date_surprise  ...  \\\n",
       "23088  00:01:00   0.0    0.0     0.0 1997-09-10 00:01:00           NaN  ...   \n",
       "23089  00:02:00   0.0    0.0     0.0 1997-09-10 00:02:00           NaN  ...   \n",
       "23090  00:03:00   0.0    0.0     0.0 1997-09-10 00:03:00           NaN  ...   \n",
       "23091  00:04:00   0.0    0.0     0.0 1997-09-10 00:04:00           NaN  ...   \n",
       "23092  00:05:00   0.0    0.0     0.0 1997-09-10 00:05:00           NaN  ...   \n",
       "...         ...   ...    ...     ...                 ...           ...  ...   \n",
       "17882       NaN   NaN    NaN     NaN                 NaT           NaN  ...   \n",
       "19078       NaN   NaN    NaN     NaN                 NaT           NaN  ...   \n",
       "19096       NaN   NaN    NaN     NaN                 NaT           NaN  ...   \n",
       "19097       NaN   NaN    NaN     NaN                 NaT           NaN  ...   \n",
       "23087       NaN   NaN    NaN     NaN                 NaT           NaN  ...   \n",
       "\n",
       "      Flag     _merge Surprise Occurred First Post Surprise N_Return  \\\n",
       "23088  NaN  left_only             False               False      NaN   \n",
       "23089  NaN  left_only             False               False      NaN   \n",
       "23090  NaN  left_only             False               False      NaN   \n",
       "23091  NaN  left_only             False               False      NaN   \n",
       "23092  NaN  left_only             False               False      NaN   \n",
       "...    ...        ...               ...                 ...      ...   \n",
       "17882  NaN        NaN               NaN                 NaN      NaN   \n",
       "19078  NaN        NaN               NaN                 NaN      NaN   \n",
       "19096  NaN        NaN               NaN                 NaN      NaN   \n",
       "19097  NaN        NaN               NaN                 NaN      NaN   \n",
       "23087  NaN        NaN               NaN                 NaN      NaN   \n",
       "\n",
       "      N_Return_half N_Return_double Return Return_half Return_double  \n",
       "23088           NaN             NaN    NaN         NaN           NaN  \n",
       "23089           NaN             NaN    NaN         NaN           NaN  \n",
       "23090           NaN             NaN    NaN         NaN           NaN  \n",
       "23091           NaN             NaN    NaN         NaN           NaN  \n",
       "23092           NaN             NaN    NaN         NaN           NaN  \n",
       "...             ...             ...    ...         ...           ...  \n",
       "17882           NaN             NaN    NaN         NaN           NaN  \n",
       "19078           NaN             NaN    NaN         NaN           NaN  \n",
       "19096           NaN             NaN    NaN         NaN           NaN  \n",
       "19097           NaN             NaN    NaN         NaN           NaN  \n",
       "23087           NaN             NaN    NaN         NaN           NaN  \n",
       "\n",
       "[9695685 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapping = df_mapping.rename(columns={'All Blomberg indicators': 'Ticker'})\n",
    "\n",
    "df_combined = pd.merge(df_mapping, df_combined, on='Ticker', how='outer')\n",
    "\n",
    "df_combined = df_combined.sort_values(by='DateTime', ascending=True)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "economic_data = economic_data.copy()\n",
    "economic_data['DateTime'] = pd.to_datetime(economic_data.index).floor('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f606d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Profit measure\n",
    "df_combined['Profit'] = np.where(\n",
    "    np.isnan(df_combined['Return']),\n",
    "    np.nan,  # If Return is NaN, set Profit to NaN\n",
    "    np.where(\n",
    "        df_combined['Return'] > 2 * transaction_cost,\n",
    "        1,  # Profitable long\n",
    "        np.where(\n",
    "            -df_combined['Return'] > 2 * transaction_cost,\n",
    "            2,  # Profitable short\n",
    "            0    # Neutral (within cost bounds)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# For Profit_half measure\n",
    "df_combined['Profit_half'] = np.where(\n",
    "    np.isnan(df_combined['Return_half']),\n",
    "    np.nan,\n",
    "    np.where(\n",
    "        df_combined['Return_half'] > 2 * transaction_cost,\n",
    "        1,\n",
    "        np.where(\n",
    "            -df_combined['Return_half'] > 2 * transaction_cost,\n",
    "            2,\n",
    "            0\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# For Profit_double measure\n",
    "df_combined['Profit_double'] = np.where(\n",
    "    np.isnan(df_combined['Return_double']),\n",
    "    np.nan,\n",
    "    np.where(\n",
    "        df_combined['Return_double'] > 2 * transaction_cost,\n",
    "        1,\n",
    "        np.where(\n",
    "            -df_combined['Return_double'] > 2 * transaction_cost,\n",
    "            2,\n",
    "            0\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23332417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intm = df_combined[df_combined['Surprise Occurred'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Return'] = df_combined['Return'].shift(-1)\n",
    "df_combined['Return_half'] = df_combined['Return_half'].shift(-1)\n",
    "df_combined['Return_double'] = df_combined['Return_double'].shift(-1)\n",
    "\n",
    "df_combined['Profit'] = df_combined['Profit'].shift(-1)\n",
    "df_combined['Profit_half'] = df_combined['Profit_half'].shift(-1)\n",
    "df_combined['Profit_double'] = df_combined['Profit_double'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385be83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>Broad indicator</th>\n",
       "      <th>Date_es</th>\n",
       "      <th>Time_es</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Date_surprise</th>\n",
       "      <th>...</th>\n",
       "      <th>First Post Surprise</th>\n",
       "      <th>N_Return</th>\n",
       "      <th>N_Return_half</th>\n",
       "      <th>N_Return_double</th>\n",
       "      <th>Return</th>\n",
       "      <th>Return_half</th>\n",
       "      <th>Return_double</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Profit_half</th>\n",
       "      <th>Profit_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8014</th>\n",
       "      <td>GDP CQOQ Index</td>\n",
       "      <td>GDP Quarterly Change QoQ</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>03/26/1998</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1355.65</td>\n",
       "      <td>1355.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-03-26 07:30:00</td>\n",
       "      <td>1998-03-26</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9582</th>\n",
       "      <td>INJCJC Index</td>\n",
       "      <td>Initial Jobless Claims</td>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>06/04/1998</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1322.96</td>\n",
       "      <td>1323.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-06-04 07:30:00</td>\n",
       "      <td>1998-06-04</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18128</th>\n",
       "      <td>PPI CHNG Index</td>\n",
       "      <td>Producer Price Index (PPI) Monthly Change</td>\n",
       "      <td>Inflation rate</td>\n",
       "      <td>06/12/1998</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1337.57</td>\n",
       "      <td>1337.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-06-12 07:30:00</td>\n",
       "      <td>1998-06-12</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18738</th>\n",
       "      <td>PXFECHNG Index</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/12/1998</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1337.57</td>\n",
       "      <td>1337.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-06-12 07:30:00</td>\n",
       "      <td>1998-06-12</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>-0.001353</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292686</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/16/1998</td>\n",
       "      <td>07:29:00</td>\n",
       "      <td>1321.86</td>\n",
       "      <td>1321.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-06-16 07:29:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ticker                                Description  \\\n",
       "8014    GDP CQOQ Index                   GDP Quarterly Change QoQ   \n",
       "9582      INJCJC Index                     Initial Jobless Claims   \n",
       "18128   PPI CHNG Index  Producer Price Index (PPI) Monthly Change   \n",
       "18738   PXFECHNG Index                                        NaN   \n",
       "292686             NaN                                        NaN   \n",
       "\n",
       "          Broad indicator     Date_es   Time_es     Open    Close  Volume  \\\n",
       "8014      GDP growth rate  03/26/1998  07:30:00  1355.65  1355.96     0.0   \n",
       "9582    Unemployment rate  06/04/1998  07:30:00  1322.96  1323.57     0.0   \n",
       "18128      Inflation rate  06/12/1998  07:30:00  1337.57  1337.57     0.0   \n",
       "18738                 NaN  06/12/1998  07:30:00  1337.57  1337.57     0.0   \n",
       "292686                NaN  06/16/1998  07:29:00  1321.86  1321.86     0.0   \n",
       "\n",
       "                  DateTime Date_surprise  ... First Post Surprise  N_Return  \\\n",
       "8014   1998-03-26 07:30:00    1998-03-26  ...               False       NaN   \n",
       "9582   1998-06-04 07:30:00    1998-06-04  ...               False       NaN   \n",
       "18128  1998-06-12 07:30:00    1998-06-12  ...               False       NaN   \n",
       "18738  1998-06-12 07:30:00    1998-06-12  ...                True -0.001129   \n",
       "292686 1998-06-16 07:29:00           NaN  ...               False       NaN   \n",
       "\n",
       "       N_Return_half N_Return_double    Return Return_half Return_double  \\\n",
       "8014             NaN             NaN -0.000229    0.001350      0.000000   \n",
       "9582             NaN             NaN -0.000461    0.000227     -0.000461   \n",
       "18128            NaN             NaN -0.001129   -0.001129      0.000680   \n",
       "18738      -0.001129         0.00068 -0.001353   -0.001129      0.000224   \n",
       "292686           NaN             NaN -0.000461    0.000000      0.000227   \n",
       "\n",
       "       Profit Profit_half Profit_double  \n",
       "8014      2.0         1.0           0.0  \n",
       "9582      2.0         1.0           2.0  \n",
       "18128     2.0         2.0           1.0  \n",
       "18738     2.0         2.0           1.0  \n",
       "292686    2.0         0.0           1.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing if the profit classifier was correctly created by looking at some rows for when classification variable = 0,1 & 2\n",
    "\n",
    "df_combined[df_combined['Profit'] == 2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230989dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profit\n",
       "1.0    11292\n",
       "2.0    10834\n",
       "0.0      942\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['Profit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e6bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\1017602337.py:25: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f'UpDown{period}'] = np.sign(df['Open'].pct_change(period))\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\1017602337.py:25: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f'UpDown{period}'] = np.sign(df['Open'].pct_change(period))\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\1017602337.py:25: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f'UpDown{period}'] = np.sign(df['Open'].pct_change(period))\n"
     ]
    }
   ],
   "source": [
    "# Now we create the technical explanatory variables based on literature\n",
    "\n",
    "def create_technical_features(df):\n",
    "    \"\"\"\n",
    "    Creates all technical features for a dataframe containing price/volume data\n",
    "    and three return columns (Return, Return_half, Return_double)\n",
    "    \"\"\"\n",
    "    # 1. Original Features\n",
    "    df['Volume'] = df['Volume']\n",
    "    df['Price'] = df['Open']\n",
    "\n",
    "    # 2. Simple Moving Averages (now includes all required windows)\n",
    "    ma_windows = [5, 10, 15, 20, 50, 100, 200]  # Added missing windows for crossovers\n",
    "    for window in ma_windows:\n",
    "        df[f'SMA{window}'] = df['Open'].rolling(window).mean()\n",
    "\n",
    "    # 3. Moving Average Crossovers (now all SMAs exist)\n",
    "    for window in [5, 10, 15, 20, 50, 100, 200]:\n",
    "        # No more need for existence check since we created all SMAs\n",
    "        df[f'SMA{window}Cross'] = (df['Open'] > df[f'SMA{window}']).astype(int)\n",
    "\n",
    "    # 4. Consecutive Price Trends\n",
    "    trend_periods = [10, 15, 50]\n",
    "    for period in trend_periods:\n",
    "        df[f'UpDown{period}'] = np.sign(df['Open'].pct_change(period))\n",
    "\n",
    "    # Ensure we keep the original return columns\n",
    "    return_cols = ['Return', 'Return_half', 'Return_double']\n",
    "    for col in return_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col]  # Maintain existing returns\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df_combined must contain: 'volume', 'close' columns plus the 3 return columns\n",
    "df_combined = create_technical_features(df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43062b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticker', 'Description', 'Broad indicator', 'Date_es', 'Time_es',\n",
       "       'Open', 'Close', 'Volume', 'DateTime', 'Date_surprise', 'Period',\n",
       "       'Event', 'Actual', 'Prior', 'Revised', 'Freq.', 'First Rev.',\n",
       "       'Last Rev.', 'Time_surprise', 'C', 'Category', 'Subcategory', 'R',\n",
       "       'Day', 'Surv(M)', '# Ests.', 'Std Dev', 'Surprise', 'Country/Region',\n",
       "       'Flag', '_merge', 'Surprise Occurred', 'First Post Surprise',\n",
       "       'N_Return', 'N_Return_half', 'N_Return_double', 'Return', 'Return_half',\n",
       "       'Return_double', 'Profit', 'Profit_half', 'Profit_double', 'Price',\n",
       "       'SMA5', 'SMA10', 'SMA15', 'SMA20', 'SMA50', 'SMA100', 'SMA200',\n",
       "       'SMA5Cross', 'SMA10Cross', 'SMA15Cross', 'SMA20Cross', 'SMA50Cross',\n",
       "       'SMA100Cross', 'SMA200Cross', 'UpDown10', 'UpDown15', 'UpDown50',\n",
       "       'Volume_L1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['Volume_L1'] = df_combined['Volume'].shift(1)\n",
    "\n",
    "df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the Ticker column\n",
    "ticker_dummies = pd.get_dummies(df_combined['Ticker'], prefix='Ticker')\n",
    "\n",
    "# Create new numerical ticker representation\n",
    "df_combined = pd.concat([df_combined, ticker_dummies], axis=1)\n",
    "\n",
    "# Create list of all ticker dummy columns\n",
    "ticker_cols = [col for col in df_combined.columns if col.startswith('Ticker_')]\n",
    "\n",
    "# Update feature columns to use dummy variables instead of original Ticker\n",
    "feature_cols = [\n",
    "    'Surprise', 'Volume_L1', 'R','SMA5', 'SMA10',\n",
    "    'SMA20', 'SMA200', 'SMA5Cross', 'SMA10Cross','SMA15Cross',\n",
    "    'SMA20Cross', 'SMA50Cross', 'SMA100Cross', 'SMA200Cross', 'UpDown10',\n",
    "    'UpDown15', 'UpDown50'\n",
    "] + ticker_cols  # Add the one-hot encoded ticker columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47554fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only rows where Profit label is available\n",
    "df_ml = df_combined[df_combined['Profit'].notna()].copy()\n",
    "df_ml = df_ml.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5019d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Total_Return  Total_Return_half  Total_Return_double\n",
      "count  9.695639e+06       9.695649e+06         9.695619e+06\n",
      "mean   4.360076e-06       2.189318e-06         8.721504e-06\n",
      "std    1.427892e-03       1.018879e-03         2.020539e-03\n",
      "min   -7.415265e-02      -5.416842e-02        -7.415265e-02\n",
      "25%   -3.741622e-04      -2.476948e-04        -5.254089e-04\n",
      "50%    0.000000e+00       0.000000e+00         0.000000e+00\n",
      "75%    4.025391e-04       2.645411e-04         5.904931e-04\n",
      "max    6.199723e-02       5.604819e-02         1.096072e-01\n",
      "Total_Return           0.000004\n",
      "Total_Return_half      0.000002\n",
      "Total_Return_double    0.000009\n",
      "dtype: float64\n",
      "Return           0.000325\n",
      "Return_half     -0.001230\n",
      "Return_double   -0.000822\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_combined is your DataFrame and holding_period is defined\n",
    "# Example setup (replace with your actual data loading)\n",
    "# data = {'Open': np.random.rand(100) * 100}\n",
    "# df_combined = pd.DataFrame(data)\n",
    "# df_combined.loc[np.random.choice(df_combined.index, 10, replace=False), 'Open'] = 0 # Introduce some zeros\n",
    "# holding_period = 10\n",
    "\n",
    "# Ensure holding periods are integers\n",
    "hp = int(holding_period)\n",
    "hp_half = int(holding_period * 0.5)\n",
    "hp_double = int(holding_period * 2)\n",
    "\n",
    "# --- Optimized Calculation ---\n",
    "\n",
    "# Get the current 'Open' price\n",
    "current_price = df_combined['Open']\n",
    "\n",
    "# Get the future 'Open' prices using shift()\n",
    "# shift(-n) shifts the data 'n' rows upwards (getting future values)\n",
    "future_price_std = df_combined['Open'].shift(-hp)\n",
    "future_price_half = df_combined['Open'].shift(-hp_half)\n",
    "future_price_double = df_combined['Open'].shift(-hp_double)\n",
    "\n",
    "# Calculate returns using vectorized operations\n",
    "# Use np.where to handle division by zero (current_price == 0)\n",
    "df_combined['Total_Return'] = np.where(\n",
    "    current_price != 0,\n",
    "    (future_price_std - current_price) / current_price,\n",
    "    np.nan  # Assign NaN if current_price is 0\n",
    ")\n",
    "\n",
    "df_combined['Total_Return_half'] = np.where(\n",
    "    current_price != 0,\n",
    "    (future_price_half - current_price) / current_price,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "df_combined['Total_Return_double'] = np.where(\n",
    "    current_price != 0,\n",
    "    (future_price_double - current_price) / current_price,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# print summary stats for the new created columns\n",
    "print(df_combined[['Total_Return', 'Total_Return_half', 'Total_Return_double']].describe())\n",
    "\n",
    "# print mean for new columns   \n",
    "print(df_combined[['Total_Return', 'Total_Return_half', 'Total_Return_double']].mean())\n",
    "\n",
    "print(df_combined[['Return', 'Return_half', 'Return_double']].mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67440a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "# --- 1. Set Start and End Dates ---\n",
    "start = datetime.datetime(1997, 1, 1)\n",
    "end = datetime.datetime.today()\n",
    "\n",
    "# --- 2. Get GDP Growth Data ---\n",
    "gdp_gr = pdr.DataReader('A191RL1Q225SBEA', 'fred', start, end)\n",
    "\n",
    "# Create gdp_gr_ml dataframe\n",
    "gdp_gr_ml = gdp_gr.reset_index()\n",
    "gdp_gr_ml.rename(columns={'A191RL1Q225SBEA': 'gdp_gr'}, inplace=True)\n",
    "gdp_gr_ml['DateTime'] = pd.to_datetime(gdp_gr_ml['DATE']) + pd.Timedelta(hours=23, minutes=59)\n",
    "gdp_gr_ml = gdp_gr_ml[['DateTime', 'gdp_gr']]\n",
    "\n",
    "# --- 3. Get VIX Data ---\n",
    "vix = pdr.DataReader('VIXCLS', 'fred', start, end)\n",
    "\n",
    "# Create vix_ml dataframe\n",
    "vix_ml = vix.reset_index()\n",
    "vix_ml.rename(columns={'VIXCLS': 'VIX'}, inplace=True)\n",
    "vix_ml['DateTime'] = pd.to_datetime(vix_ml['DATE']) + pd.Timedelta(hours=23, minutes=59)\n",
    "vix_ml = vix_ml[['DateTime', 'VIX']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d39835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>gdp_gr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-01-01 23:59:00</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-04-01 23:59:00</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-07-01 23:59:00</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-10-01 23:59:00</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-01-01 23:59:00</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023-10-01 23:59:00</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2024-01-01 23:59:00</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2024-04-01 23:59:00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2024-07-01 23:59:00</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2024-10-01 23:59:00</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DateTime  gdp_gr\n",
       "0   1997-01-01 23:59:00     2.6\n",
       "1   1997-04-01 23:59:00     6.8\n",
       "2   1997-07-01 23:59:00     5.1\n",
       "3   1997-10-01 23:59:00     3.5\n",
       "4   1998-01-01 23:59:00     4.1\n",
       "..                  ...     ...\n",
       "107 2023-10-01 23:59:00     3.2\n",
       "108 2024-01-01 23:59:00     1.6\n",
       "109 2024-04-01 23:59:00     3.0\n",
       "110 2024-07-01 23:59:00     3.1\n",
       "111 2024-10-01 23:59:00     2.4\n",
       "\n",
       "[112 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop DateTime with year 2025\n",
    "gdp_gr_ml = gdp_gr_ml[gdp_gr_ml['DateTime'].dt.year != 2025]\n",
    "\n",
    "gdp_gr_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677051af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>VIX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-01-01 23:59:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-01-02 23:59:00</td>\n",
       "      <td>21.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-01-03 23:59:00</td>\n",
       "      <td>19.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-01-06 23:59:00</td>\n",
       "      <td>19.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-01-07 23:59:00</td>\n",
       "      <td>19.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>2025-05-19 23:59:00</td>\n",
       "      <td>18.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7404</th>\n",
       "      <td>2025-05-20 23:59:00</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>2025-05-21 23:59:00</td>\n",
       "      <td>20.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7406</th>\n",
       "      <td>2025-05-22 23:59:00</td>\n",
       "      <td>20.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>2025-05-23 23:59:00</td>\n",
       "      <td>22.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7408 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                DateTime    VIX\n",
       "0    1997-01-01 23:59:00    NaN\n",
       "1    1997-01-02 23:59:00  21.14\n",
       "2    1997-01-03 23:59:00  19.13\n",
       "3    1997-01-06 23:59:00  19.89\n",
       "4    1997-01-07 23:59:00  19.35\n",
       "...                  ...    ...\n",
       "7403 2025-05-19 23:59:00  18.14\n",
       "7404 2025-05-20 23:59:00  18.09\n",
       "7405 2025-05-21 23:59:00  20.87\n",
       "7406 2025-05-22 23:59:00  20.28\n",
       "7407 2025-05-23 23:59:00  22.29\n",
       "\n",
       "[7408 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vix_ml = vix_ml[:-3]\n",
    "\n",
    "vix_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c3012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>Broad indicator</th>\n",
       "      <th>Date_es</th>\n",
       "      <th>Time_es</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticker_USPHTMOM Index</th>\n",
       "      <th>Ticker_USPHTYOY Index</th>\n",
       "      <th>Ticker_USTBTOT Index</th>\n",
       "      <th>Ticker_USTGTTCB Index</th>\n",
       "      <th>Ticker_USUDMAER Index</th>\n",
       "      <th>Ticker_USURTOT Index</th>\n",
       "      <th>Ticker_USWHMANS Index</th>\n",
       "      <th>Ticker_USWHTOT Index</th>\n",
       "      <th>Ticker_VNCCCMOM Index</th>\n",
       "      <th>Ticker_VNCCTOT Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8013</td>\n",
       "      <td>GDP CQOQ Index</td>\n",
       "      <td>GDP Quarterly Change QoQ</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>12/23/1997</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1189.71</td>\n",
       "      <td>1189.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-12-23 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8014</td>\n",
       "      <td>GDP CQOQ Index</td>\n",
       "      <td>GDP Quarterly Change QoQ</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>03/26/1998</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1355.65</td>\n",
       "      <td>1355.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-03-26 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8015</td>\n",
       "      <td>GDP CQOQ Index</td>\n",
       "      <td>GDP Quarterly Change QoQ</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>04/30/1998</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1338.85</td>\n",
       "      <td>1338.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-04-30 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14293</td>\n",
       "      <td>NAPMPMI Index</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/01/1998</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>1335.49</td>\n",
       "      <td>1334.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-06-01 09:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15945</td>\n",
       "      <td>NHSLTOT Index</td>\n",
       "      <td>New Home Sales Total</td>\n",
       "      <td>Building permits - new private housing units a...</td>\n",
       "      <td>06/02/1998</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1342.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-06-02 09:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23063</th>\n",
       "      <td>15553</td>\n",
       "      <td>NHCHATCH Index</td>\n",
       "      <td>New Home Sales (Annualized)</td>\n",
       "      <td>Building permits - new private housing units a...</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>6145.50</td>\n",
       "      <td>6145.75</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2024-12-18 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23064</th>\n",
       "      <td>15726</td>\n",
       "      <td>NHCHSTCH Index</td>\n",
       "      <td>New Home Sales Change</td>\n",
       "      <td>Building permits - new private housing units a...</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>6145.50</td>\n",
       "      <td>6145.75</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2024-12-18 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23065</th>\n",
       "      <td>16836</td>\n",
       "      <td>NHSPSTOT Index</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>6145.50</td>\n",
       "      <td>6145.75</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2024-12-18 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23066</th>\n",
       "      <td>5866</td>\n",
       "      <td>DOTDY1MD Index</td>\n",
       "      <td>Department of Transportation: International Ai...</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>6135.75</td>\n",
       "      <td>6136.00</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2024-12-18 13:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23067</th>\n",
       "      <td>5867</td>\n",
       "      <td>DOTDY2MD Index</td>\n",
       "      <td>Department of Transportation: Systemwide Air R...</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>6135.75</td>\n",
       "      <td>6136.00</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2024-12-18 13:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23068 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index          Ticker  \\\n",
       "0       8013  GDP CQOQ Index   \n",
       "1       8014  GDP CQOQ Index   \n",
       "2       8015  GDP CQOQ Index   \n",
       "3      14293   NAPMPMI Index   \n",
       "4      15945   NHSLTOT Index   \n",
       "...      ...             ...   \n",
       "23063  15553  NHCHATCH Index   \n",
       "23064  15726  NHCHSTCH Index   \n",
       "23065  16836  NHSPSTOT Index   \n",
       "23066   5866  DOTDY1MD Index   \n",
       "23067   5867  DOTDY2MD Index   \n",
       "\n",
       "                                             Description  \\\n",
       "0                               GDP Quarterly Change QoQ   \n",
       "1                               GDP Quarterly Change QoQ   \n",
       "2                               GDP Quarterly Change QoQ   \n",
       "3                                                    NaN   \n",
       "4                                   New Home Sales Total   \n",
       "...                                                  ...   \n",
       "23063                        New Home Sales (Annualized)   \n",
       "23064                              New Home Sales Change   \n",
       "23065                                                NaN   \n",
       "23066  Department of Transportation: International Ai...   \n",
       "23067  Department of Transportation: Systemwide Air R...   \n",
       "\n",
       "                                         Broad indicator     Date_es  \\\n",
       "0                                        GDP growth rate  12/23/1997   \n",
       "1                                        GDP growth rate  03/26/1998   \n",
       "2                                        GDP growth rate  04/30/1998   \n",
       "3                                                    NaN  06/01/1998   \n",
       "4      Building permits - new private housing units a...  06/02/1998   \n",
       "...                                                  ...         ...   \n",
       "23063  Building permits - new private housing units a...  12/18/2024   \n",
       "23064  Building permits - new private housing units a...  12/18/2024   \n",
       "23065                                                NaN  12/18/2024   \n",
       "23066                                    GDP growth rate  12/18/2024   \n",
       "23067                                    GDP growth rate  12/18/2024   \n",
       "\n",
       "        Time_es     Open    Close  Volume            DateTime  ...  \\\n",
       "0      07:30:00  1189.71  1189.71     0.0 1997-12-23 07:30:00  ...   \n",
       "1      07:30:00  1355.65  1355.96     0.0 1998-03-26 07:30:00  ...   \n",
       "2      07:30:00  1338.85  1338.85     0.0 1998-04-30 07:30:00  ...   \n",
       "3      09:00:00  1335.49  1334.87     0.0 1998-06-01 09:00:00  ...   \n",
       "4      09:00:00  1343.12  1342.51     0.0 1998-06-02 09:00:00  ...   \n",
       "...         ...      ...      ...     ...                 ...  ...   \n",
       "23063  07:30:00  6145.50  6145.75   131.0 2024-12-18 07:30:00  ...   \n",
       "23064  07:30:00  6145.50  6145.75   131.0 2024-12-18 07:30:00  ...   \n",
       "23065  07:30:00  6145.50  6145.75   131.0 2024-12-18 07:30:00  ...   \n",
       "23066  13:00:00  6135.75  6136.00   801.0 2024-12-18 13:00:00  ...   \n",
       "23067  13:00:00  6135.75  6136.00   801.0 2024-12-18 13:00:00  ...   \n",
       "\n",
       "      Ticker_USPHTMOM Index Ticker_USPHTYOY Index Ticker_USTBTOT Index  \\\n",
       "0                     False                 False                False   \n",
       "1                     False                 False                False   \n",
       "2                     False                 False                False   \n",
       "3                     False                 False                False   \n",
       "4                     False                 False                False   \n",
       "...                     ...                   ...                  ...   \n",
       "23063                 False                 False                False   \n",
       "23064                 False                 False                False   \n",
       "23065                 False                 False                False   \n",
       "23066                 False                 False                False   \n",
       "23067                 False                 False                False   \n",
       "\n",
       "      Ticker_USTGTTCB Index Ticker_USUDMAER Index Ticker_USURTOT Index  \\\n",
       "0                     False                 False                False   \n",
       "1                     False                 False                False   \n",
       "2                     False                 False                False   \n",
       "3                     False                 False                False   \n",
       "4                     False                 False                False   \n",
       "...                     ...                   ...                  ...   \n",
       "23063                 False                 False                False   \n",
       "23064                 False                 False                False   \n",
       "23065                 False                 False                False   \n",
       "23066                 False                 False                False   \n",
       "23067                 False                 False                False   \n",
       "\n",
       "      Ticker_USWHMANS Index Ticker_USWHTOT Index Ticker_VNCCCMOM Index  \\\n",
       "0                     False                False                 False   \n",
       "1                     False                False                 False   \n",
       "2                     False                False                 False   \n",
       "3                     False                False                 False   \n",
       "4                     False                False                 False   \n",
       "...                     ...                  ...                   ...   \n",
       "23063                 False                False                 False   \n",
       "23064                 False                False                 False   \n",
       "23065                 False                False                 False   \n",
       "23066                 False                False                 False   \n",
       "23067                 False                False                 False   \n",
       "\n",
       "      Ticker_VNCCTOT Index  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  \n",
       "...                    ...  \n",
       "23063                False  \n",
       "23064                False  \n",
       "23065                False  \n",
       "23066                False  \n",
       "23067                False  \n",
       "\n",
       "[23068 rows x 243 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe3179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>Broad indicator</th>\n",
       "      <th>Date_es</th>\n",
       "      <th>Time_es</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticker_USTBTOT Index</th>\n",
       "      <th>Ticker_USTGTTCB Index</th>\n",
       "      <th>Ticker_USUDMAER Index</th>\n",
       "      <th>Ticker_USURTOT Index</th>\n",
       "      <th>Ticker_USWHMANS Index</th>\n",
       "      <th>Ticker_USWHTOT Index</th>\n",
       "      <th>Ticker_VNCCCMOM Index</th>\n",
       "      <th>Ticker_VNCCTOT Index</th>\n",
       "      <th>last_gdp_gr</th>\n",
       "      <th>last_vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8013</td>\n",
       "      <td>GDP CQOQ Index</td>\n",
       "      <td>GDP Quarterly Change QoQ</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>12/23/1997</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1189.71</td>\n",
       "      <td>1189.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-12-23 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>28.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8014</td>\n",
       "      <td>GDP CQOQ Index</td>\n",
       "      <td>GDP Quarterly Change QoQ</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>03/26/1998</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1355.65</td>\n",
       "      <td>1355.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-03-26 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.1</td>\n",
       "      <td>22.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8015</td>\n",
       "      <td>GDP CQOQ Index</td>\n",
       "      <td>GDP Quarterly Change QoQ</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>04/30/1998</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>1338.85</td>\n",
       "      <td>1338.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-04-30 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.8</td>\n",
       "      <td>22.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14293</td>\n",
       "      <td>NAPMPMI Index</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/01/1998</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>1335.49</td>\n",
       "      <td>1334.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-06-01 09:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.8</td>\n",
       "      <td>21.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15945</td>\n",
       "      <td>NHSLTOT Index</td>\n",
       "      <td>New Home Sales Total</td>\n",
       "      <td>Building permits - new private housing units a...</td>\n",
       "      <td>06/02/1998</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1342.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998-06-02 09:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.8</td>\n",
       "      <td>22.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23063</th>\n",
       "      <td>15726</td>\n",
       "      <td>NHCHSTCH Index</td>\n",
       "      <td>New Home Sales Change</td>\n",
       "      <td>Building permits - new private housing units a...</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>6145.50</td>\n",
       "      <td>6145.75</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2024-12-18 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>15.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23064</th>\n",
       "      <td>21285</td>\n",
       "      <td>USCABAL Index</td>\n",
       "      <td>U.S. Current Account Balance</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>6145.50</td>\n",
       "      <td>6145.75</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2024-12-18 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>15.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23065</th>\n",
       "      <td>16836</td>\n",
       "      <td>NHSPSTOT Index</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>6145.50</td>\n",
       "      <td>6145.75</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2024-12-18 07:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>15.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23066</th>\n",
       "      <td>5866</td>\n",
       "      <td>DOTDY1MD Index</td>\n",
       "      <td>Department of Transportation: International Ai...</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>6135.75</td>\n",
       "      <td>6136.00</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2024-12-18 13:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>15.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23067</th>\n",
       "      <td>5867</td>\n",
       "      <td>DOTDY2MD Index</td>\n",
       "      <td>Department of Transportation: Systemwide Air R...</td>\n",
       "      <td>GDP growth rate</td>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>6135.75</td>\n",
       "      <td>6136.00</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2024-12-18 13:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>15.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23068 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index          Ticker  \\\n",
       "0       8013  GDP CQOQ Index   \n",
       "1       8014  GDP CQOQ Index   \n",
       "2       8015  GDP CQOQ Index   \n",
       "3      14293   NAPMPMI Index   \n",
       "4      15945   NHSLTOT Index   \n",
       "...      ...             ...   \n",
       "23063  15726  NHCHSTCH Index   \n",
       "23064  21285   USCABAL Index   \n",
       "23065  16836  NHSPSTOT Index   \n",
       "23066   5866  DOTDY1MD Index   \n",
       "23067   5867  DOTDY2MD Index   \n",
       "\n",
       "                                             Description  \\\n",
       "0                               GDP Quarterly Change QoQ   \n",
       "1                               GDP Quarterly Change QoQ   \n",
       "2                               GDP Quarterly Change QoQ   \n",
       "3                                                    NaN   \n",
       "4                                   New Home Sales Total   \n",
       "...                                                  ...   \n",
       "23063                              New Home Sales Change   \n",
       "23064                       U.S. Current Account Balance   \n",
       "23065                                                NaN   \n",
       "23066  Department of Transportation: International Ai...   \n",
       "23067  Department of Transportation: Systemwide Air R...   \n",
       "\n",
       "                                         Broad indicator     Date_es  \\\n",
       "0                                        GDP growth rate  12/23/1997   \n",
       "1                                        GDP growth rate  03/26/1998   \n",
       "2                                        GDP growth rate  04/30/1998   \n",
       "3                                                    NaN  06/01/1998   \n",
       "4      Building permits - new private housing units a...  06/02/1998   \n",
       "...                                                  ...         ...   \n",
       "23063  Building permits - new private housing units a...  12/18/2024   \n",
       "23064                                    GDP growth rate  12/18/2024   \n",
       "23065                                                NaN  12/18/2024   \n",
       "23066                                    GDP growth rate  12/18/2024   \n",
       "23067                                    GDP growth rate  12/18/2024   \n",
       "\n",
       "        Time_es     Open    Close  Volume            DateTime  ...  \\\n",
       "0      07:30:00  1189.71  1189.71     0.0 1997-12-23 07:30:00  ...   \n",
       "1      07:30:00  1355.65  1355.96     0.0 1998-03-26 07:30:00  ...   \n",
       "2      07:30:00  1338.85  1338.85     0.0 1998-04-30 07:30:00  ...   \n",
       "3      09:00:00  1335.49  1334.87     0.0 1998-06-01 09:00:00  ...   \n",
       "4      09:00:00  1343.12  1342.51     0.0 1998-06-02 09:00:00  ...   \n",
       "...         ...      ...      ...     ...                 ...  ...   \n",
       "23063  07:30:00  6145.50  6145.75   131.0 2024-12-18 07:30:00  ...   \n",
       "23064  07:30:00  6145.50  6145.75   131.0 2024-12-18 07:30:00  ...   \n",
       "23065  07:30:00  6145.50  6145.75   131.0 2024-12-18 07:30:00  ...   \n",
       "23066  13:00:00  6135.75  6136.00   801.0 2024-12-18 13:00:00  ...   \n",
       "23067  13:00:00  6135.75  6136.00   801.0 2024-12-18 13:00:00  ...   \n",
       "\n",
       "      Ticker_USTBTOT Index Ticker_USTGTTCB Index Ticker_USUDMAER Index  \\\n",
       "0                    False                 False                 False   \n",
       "1                    False                 False                 False   \n",
       "2                    False                 False                 False   \n",
       "3                    False                 False                 False   \n",
       "4                    False                 False                 False   \n",
       "...                    ...                   ...                   ...   \n",
       "23063                False                 False                 False   \n",
       "23064                False                 False                 False   \n",
       "23065                False                 False                 False   \n",
       "23066                False                 False                 False   \n",
       "23067                False                 False                 False   \n",
       "\n",
       "      Ticker_USURTOT Index Ticker_USWHMANS Index Ticker_USWHTOT Index  \\\n",
       "0                    False                 False                False   \n",
       "1                    False                 False                False   \n",
       "2                    False                 False                False   \n",
       "3                    False                 False                False   \n",
       "4                    False                 False                False   \n",
       "...                    ...                   ...                  ...   \n",
       "23063                False                 False                False   \n",
       "23064                False                 False                False   \n",
       "23065                False                 False                False   \n",
       "23066                False                 False                False   \n",
       "23067                False                 False                False   \n",
       "\n",
       "      Ticker_VNCCCMOM Index Ticker_VNCCTOT Index last_gdp_gr last_vix  \n",
       "0                     False                False         3.5    28.56  \n",
       "1                     False                False         4.1    22.54  \n",
       "2                     False                False         3.8    22.78  \n",
       "3                     False                False         3.8    21.32  \n",
       "4                     False                False         3.8    22.83  \n",
       "...                     ...                  ...         ...      ...  \n",
       "23063                 False                False         2.4    15.87  \n",
       "23064                 False                False         2.4    15.87  \n",
       "23065                 False                False         2.4    15.87  \n",
       "23066                 False                False         2.4    15.87  \n",
       "23067                 False                False         2.4    15.87  \n",
       "\n",
       "[23068 rows x 245 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First make sure all are sorted by DateTime (required for merge_asof)\n",
    "df_ml = df_ml.sort_values('DateTime')\n",
    "gdp_gr_ml = gdp_gr_ml.sort_values('DateTime')\n",
    "vix_ml = vix_ml.sort_values('DateTime')\n",
    "\n",
    "# Merge the last known GDP growth\n",
    "df_ml = pd.merge_asof(\n",
    "    df_ml,\n",
    "    gdp_gr_ml,\n",
    "    on='DateTime',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# Merge the last known VIX\n",
    "df_ml = pd.merge_asof(\n",
    "    df_ml,\n",
    "    vix_ml,\n",
    "    on='DateTime',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# Rename the merged columns to last_gdp_gr and last_vix\n",
    "df_ml = df_ml.rename(columns={\n",
    "    'gdp_gr': 'last_gdp_gr',\n",
    "    'VIX': 'last_vix'\n",
    "})\n",
    "\n",
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d233fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values per column:\n",
      "index: 0\n",
      "Ticker: 3391\n",
      "Description: 6219\n",
      "Broad indicator: 6342\n",
      "Date_es: 0\n",
      "Time_es: 0\n",
      "Open: 0\n",
      "Close: 0\n",
      "Volume: 0\n",
      "DateTime: 0\n",
      "Date_surprise: 3391\n",
      "Period: 3391\n",
      "Event: 3391\n",
      "Actual: 3391\n",
      "Prior: 3407\n",
      "Revised: 10840\n",
      "Freq.: 3391\n",
      "First Rev.: 10840\n",
      "Last Rev.: 6954\n",
      "Time_surprise: 3391\n",
      "C: 3391\n",
      "Category: 3391\n",
      "Subcategory: 23068\n",
      "R: 3391\n",
      "Day: 3391\n",
      "Surv(M): 3391\n",
      "# Ests.: 3391\n",
      "Std Dev: 3391\n",
      "Surprise: 3391\n",
      "Country/Region: 3391\n",
      "Flag: 3391\n",
      "_merge: 0\n",
      "Surprise Occurred: 0\n",
      "First Post Surprise: 0\n",
      "N_Return: 13419\n",
      "N_Return_half: 13419\n",
      "N_Return_double: 13419\n",
      "Return: 0\n",
      "Return_half: 0\n",
      "Return_double: 0\n",
      "Profit: 0\n",
      "Profit_half: 0\n",
      "Profit_double: 0\n",
      "Price: 0\n",
      "SMA5: 0\n",
      "SMA10: 0\n",
      "SMA15: 0\n",
      "SMA20: 0\n",
      "SMA50: 0\n",
      "SMA100: 0\n",
      "SMA200: 0\n",
      "SMA5Cross: 0\n",
      "SMA10Cross: 0\n",
      "SMA15Cross: 0\n",
      "SMA20Cross: 0\n",
      "SMA50Cross: 0\n",
      "SMA100Cross: 0\n",
      "SMA200Cross: 0\n",
      "UpDown10: 0\n",
      "UpDown15: 0\n",
      "UpDown50: 0\n",
      "Volume_L1: 0\n",
      "Ticker_ACNFCOMF Index: 0\n",
      "Ticker_ADP CHNG Index: 0\n",
      "Ticker_AHE MOM% Index: 0\n",
      "Ticker_AHE YOY% Index: 0\n",
      "Ticker_AMSPPACE Index: 0\n",
      "Ticker_AWH TOTL Index: 0\n",
      "Ticker_BBRSCPYY Index: 0\n",
      "Ticker_BPGCGI Index: 0\n",
      "Ticker_CFNAI Index: 0\n",
      "Ticker_CGNOXAI% Index: 0\n",
      "Ticker_CGSHXAI% Index: 0\n",
      "Ticker_CHPMINDX Index: 0\n",
      "Ticker_CICRTOT Index: 0\n",
      "Ticker_CNSTTMOM Index: 0\n",
      "Ticker_COMFBTWR Index: 0\n",
      "Ticker_COMFCOMF Index: 0\n",
      "Ticker_CONCCONF Index: 0\n",
      "Ticker_CONCEXP Index: 0\n",
      "Ticker_CONCPSIT Index: 0\n",
      "Ticker_CONSCURR Index: 0\n",
      "Ticker_CONSEXP Index: 0\n",
      "Ticker_CONSP5MD Index: 0\n",
      "Ticker_CONSPXMD Index: 0\n",
      "Ticker_CONSSENT Index: 0\n",
      "Ticker_COSTNFR% Index: 0\n",
      "Ticker_CPI CHNG Index: 0\n",
      "Ticker_CPI XYOY Index: 0\n",
      "Ticker_CPI YOY Index: 0\n",
      "Ticker_CPTICHNG Index: 0\n",
      "Ticker_CPUPAXFE Index: 0\n",
      "Ticker_CPUPXCHG Index: 0\n",
      "Ticker_CPURNSA Index: 0\n",
      "Ticker_DFEDGBA Index: 0\n",
      "Ticker_DGNOCHNG Index: 0\n",
      "Ticker_DGNOXTCH Index: 0\n",
      "Ticker_DLQTDLQT Index: 0\n",
      "Ticker_DOTDLTMD Index: 0\n",
      "Ticker_DOTDY0MD Index: 0\n",
      "Ticker_DOTDY1MD Index: 0\n",
      "Ticker_DOTDY2MD Index: 0\n",
      "Ticker_DSERGBCC Index: 0\n",
      "Ticker_ECI SA% Index: 0\n",
      "Ticker_ECONGECC Index: 0\n",
      "Ticker_ECONUSIB Index: 0\n",
      "Ticker_EHSLMOM Index: 0\n",
      "Ticker_EHSLSL Index: 0\n",
      "Ticker_EMPRGBCI Index: 0\n",
      "Ticker_ETSLMOM Index: 0\n",
      "Ticker_ETSLTOTL Index: 0\n",
      "Ticker_EXP1CMOM Index: 0\n",
      "Ticker_EXP1CYOY Index: 0\n",
      "Ticker_FDDSSD Index: 0\n",
      "Ticker_FDEBTY Index: 0\n",
      "Ticker_FDIDFDMO Index: 0\n",
      "Ticker_FDIDSGMO Index: 0\n",
      "Ticker_FDIDSGUM Index: 0\n",
      "Ticker_FDIUFDYO Index: 0\n",
      "Ticker_FDIUSGUY Index: 0\n",
      "Ticker_FDIUSGYO Index: 0\n",
      "Ticker_FDTR Index: 0\n",
      "Ticker_FDTRFTRL Index: 0\n",
      "Ticker_FORLTOTL Index: 0\n",
      "Ticker_FRNTTNET Index: 0\n",
      "Ticker_FRNTTOTL Index: 0\n",
      "Ticker_GDP CQOQ Index: 0\n",
      "Ticker_GDP DCHG Index: 0\n",
      "Ticker_GDP PIQQ Index: 0\n",
      "Ticker_GDPCPCEC Index: 0\n",
      "Ticker_GDPCTOT% Index: 0\n",
      "Ticker_HOMEAFFR Index: 0\n",
      "Ticker_HPI PURQ Index: 0\n",
      "Ticker_HPI QOQ% Index: 0\n",
      "Ticker_HPIMMOM% Index: 0\n",
      "Ticker_HVRAHOME Index: 0\n",
      "Ticker_ICSHNATL Index: 0\n",
      "Ticker_IMP1CHNG Index: 0\n",
      "Ticker_IMP1XPM% Index: 0\n",
      "Ticker_IMP1YOY% Index: 0\n",
      "Ticker_INJCJC Index: 0\n",
      "Ticker_INJCSP Index: 0\n",
      "Ticker_IP CHNG Index: 0\n",
      "Ticker_IPMGCHNG Index: 0\n",
      "Ticker_IRRBIOER Index: 0\n",
      "Ticker_JOLTTOTL Index: 0\n",
      "Ticker_KCLSSACI Index: 0\n",
      "Ticker_KCSSMCOM Index: 0\n",
      "Ticker_LEI CHNG Index: 0\n",
      "Ticker_LHWANWPA Index: 0\n",
      "Ticker_LMCILMCC Index: 0\n",
      "Ticker_MAPMINDX Index: 0\n",
      "Ticker_MBAVCHNG Index: 0\n",
      "Ticker_MBRSWTW Index: 0\n",
      "Ticker_MBRXYOY Index: 0\n",
      "Ticker_MBRXYOYW Index: 0\n",
      "Ticker_MPMIUSCA Index: 0\n",
      "Ticker_MPMIUSMA Index: 0\n",
      "Ticker_MPMIUSSA Index: 0\n",
      "Ticker_MTIBCHNG Index: 0\n",
      "Ticker_MWINCHNG Index: 0\n",
      "Ticker_MWSLCHNG Index: 0\n",
      "Ticker_NABEEMPL Index: 0\n",
      "Ticker_NAPMEMPL Index: 0\n",
      "Ticker_NAPMNEMP Index: 0\n",
      "Ticker_NAPMNEWO Index: 0\n",
      "Ticker_NAPMNMAN Index: 0\n",
      "Ticker_NAPMNMI Index: 0\n",
      "Ticker_NAPMNNO Index: 0\n",
      "Ticker_NAPMNPRC Index: 0\n",
      "Ticker_NAPMPMI Index: 0\n",
      "Ticker_NAPMPRIC Index: 0\n",
      "Ticker_NFP CPYC Index: 0\n",
      "Ticker_NFP PCH Index: 0\n",
      "Ticker_NFP TCH Index: 0\n",
      "Ticker_NHCHATCH Index: 0\n",
      "Ticker_NHCHSTCH Index: 0\n",
      "Ticker_NHSLCHNG Index: 0\n",
      "Ticker_NHSLTOT Index: 0\n",
      "Ticker_NHSPATOT Index: 0\n",
      "Ticker_NHSPSTOT Index: 0\n",
      "Ticker_NYBLCNBA Index: 0\n",
      "Ticker_NYCNM1IR Index: 0\n",
      "Ticker_NYPMCURR Index: 0\n",
      "Ticker_OUTFGAF Index: 0\n",
      "Ticker_PCE CHNC Index: 0\n",
      "Ticker_PCE CMOM Index: 0\n",
      "Ticker_PCE CRCH Index: 0\n",
      "Ticker_PCE CYOY Index: 0\n",
      "Ticker_PCE DEFM Index: 0\n",
      "Ticker_PCE DEFY Index: 0\n",
      "Ticker_PHUCCHNG Index: 0\n",
      "Ticker_PHUCTOT Index: 0\n",
      "Ticker_PITLCHNG Index: 0\n",
      "Ticker_PNMARADI Index: 0\n",
      "Ticker_PPI CHNG Index: 0\n",
      "Ticker_PPI XYOY Index: 0\n",
      "Ticker_PPI YOY Index: 0\n",
      "Ticker_PRODNFR% Index: 0\n",
      "Ticker_PRUSTOT Index: 0\n",
      "Ticker_PXFECHNG Index: 0\n",
      "Ticker_RCHSINDX Index: 0\n",
      "Ticker_RCSSCLBC Index: 0\n",
      "Ticker_REALRAWE Index: 0\n",
      "Ticker_REALYRAE Index: 0\n",
      "Ticker_REALYRAW Index: 0\n",
      "Ticker_REDSMMOM Index: 0\n",
      "Ticker_RSRSTMOM Index: 0\n",
      "Ticker_RSTAMOM Index: 0\n",
      "Ticker_RSTAXAG% Index: 0\n",
      "Ticker_RSTAXAGM Index: 0\n",
      "Ticker_RSTAXMOM Index: 0\n",
      "Ticker_RTSDCHNG Index: 0\n",
      "Ticker_RTSDXCHG Index: 0\n",
      "Ticker_SAARDTOT Index: 0\n",
      "Ticker_SAARTOTL Index: 0\n",
      "Ticker_SBOITOTL Index: 0\n",
      "Ticker_SPCS20 Index: 0\n",
      "Ticker_SPCS20SM Index: 0\n",
      "Ticker_SPCS20Y% Index: 0\n",
      "Ticker_SPCSUSA Index: 0\n",
      "Ticker_SPCSUSAY Index: 0\n",
      "Ticker_SPCSUSQS Index: 0\n",
      "Ticker_TMNOCHNG Index: 0\n",
      "Ticker_TMNOXTM% Index: 0\n",
      "Ticker_TREFAMSP Index: 0\n",
      "Ticker_TREFPACE Index: 0\n",
      "Ticker_USCABAL Index: 0\n",
      "Ticker_USEMNCHG Index: 0\n",
      "Ticker_USHBMIDX Index: 0\n",
      "Ticker_USHETOT% Index: 0\n",
      "Ticker_USHEYOY Index: 0\n",
      "Ticker_USMMMNCH Index: 0\n",
      "Ticker_USPHTMOM Index: 0\n",
      "Ticker_USPHTYOY Index: 0\n",
      "Ticker_USTBTOT Index: 0\n",
      "Ticker_USTGTTCB Index: 0\n",
      "Ticker_USUDMAER Index: 0\n",
      "Ticker_USURTOT Index: 0\n",
      "Ticker_USWHMANS Index: 0\n",
      "Ticker_USWHTOT Index: 0\n",
      "Ticker_VNCCCMOM Index: 0\n",
      "Ticker_VNCCTOT Index: 0\n",
      "last_gdp_gr: 0\n",
      "last_vix: 456\n"
     ]
    }
   ],
   "source": [
    "# give number of missing values per column\n",
    "missing_values = df_ml.isna().sum()\n",
    "\n",
    "# print out number of missing values per column, even if 0\n",
    "print(\"Number of missing values per column:\")\n",
    "for column, count in missing_values.items():\n",
    "    print(f\"{column}: {count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23570d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for df_ml:\n",
      "              index          Open         Close        Volume  \\\n",
      "count  2.306800e+04  23068.000000  23068.000000  23068.000000   \n",
      "mean   8.559840e+05   2452.035087   2452.061627   1445.074259   \n",
      "min    0.000000e+00    638.520000    638.040000      0.000000   \n",
      "25%    6.694750e+03   1288.657500   1288.755000    245.000000   \n",
      "50%    1.345650e+04   1978.650000   1979.190000    669.000000   \n",
      "75%    2.031125e+04   3266.020000   3266.290000   1834.000000   \n",
      "max    9.693795e+06   6178.600000   6181.130000  94272.000000   \n",
      "std    2.250711e+06   1423.590578   1423.615747   2379.897848   \n",
      "\n",
      "                            DateTime  Subcategory             R       # Ests.  \\\n",
      "count                          23068          0.0  19677.000000  19677.000000   \n",
      "mean   2013-11-01 12:01:45.002600960          NaN     64.272728     37.939117   \n",
      "min              1997-12-23 07:30:00          NaN      0.000000      3.000000   \n",
      "25%              2008-05-27 07:59:45          NaN     42.963000     15.000000   \n",
      "50%              2014-06-05 07:30:00          NaN     71.851900     38.000000   \n",
      "75%              2020-01-17 09:00:00          NaN     87.407400     58.000000   \n",
      "max              2024-12-18 13:00:00          NaN     99.259300    139.000000   \n",
      "std                              NaN          NaN     28.811317     23.997498   \n",
      "\n",
      "           Surprise     N_Return  ...    SMA20Cross    SMA50Cross  \\\n",
      "count  19677.000000  9649.000000  ...  23068.000000  23068.000000   \n",
      "mean       0.038305    -0.000049  ...      0.524796      0.521848   \n",
      "min       -9.580000    -0.036467  ...      0.000000      0.000000   \n",
      "25%       -1.500000    -0.001059  ...      0.000000      0.000000   \n",
      "50%        0.020000     0.000000  ...      1.000000      1.000000   \n",
      "75%        1.540000     0.001053  ...      1.000000      1.000000   \n",
      "max       10.580000     0.028073  ...      1.000000      1.000000   \n",
      "std        2.555510     0.003246  ...      0.499396      0.499533   \n",
      "\n",
      "        SMA100Cross   SMA200Cross      UpDown10      UpDown15      UpDown50  \\\n",
      "count  23068.000000  23068.000000  23068.000000  23068.000000  23068.000000   \n",
      "mean       0.529391      0.534160      0.042873      0.054058      0.038278   \n",
      "min        0.000000      0.000000     -1.000000     -1.000000     -1.000000   \n",
      "25%        0.000000      0.000000     -1.000000     -1.000000     -1.000000   \n",
      "50%        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
      "75%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "std        0.499146      0.498843      0.947776      0.958125      0.974669   \n",
      "\n",
      "          Volume_L1   last_gdp_gr      last_vix  \n",
      "count  23068.000000  23068.000000  22612.000000  \n",
      "mean    1456.419456      2.389028     19.857231  \n",
      "min        0.000000    -28.100000      9.150000  \n",
      "25%      236.000000      1.400000     13.860000  \n",
      "50%      654.500000      2.500000     17.690000  \n",
      "75%     1854.250000      3.500000     23.330000  \n",
      "max    41667.000000     35.200000     82.690000  \n",
      "std     2161.419907      5.625788      8.569657  \n",
      "\n",
      "[8 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# print out summary statistics for the dataframe\n",
    "print(\"\\nSummary statistics for df_ml:\")\n",
    "print(df_ml.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a511af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining new input features for ML models\n",
    "\n",
    "feature_cols = [\n",
    "    'Surprise', 'Volume_L1', 'R', 'SMA5', 'SMA10',\n",
    "    'SMA20', 'SMA200', 'SMA5Cross', 'SMA10Cross', 'SMA15Cross',\n",
    "    'SMA20Cross', 'SMA50Cross', 'SMA100Cross', 'SMA200Cross', 'UpDown10',\n",
    "    'UpDown15', 'UpDown50'\n",
    "] + ticker_cols + ['last_gdp_gr', 'last_vix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5c6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Surprise',\n",
       " 'Volume_L1',\n",
       " 'R',\n",
       " 'SMA5',\n",
       " 'SMA10',\n",
       " 'SMA20',\n",
       " 'SMA200',\n",
       " 'SMA5Cross',\n",
       " 'SMA10Cross',\n",
       " 'SMA15Cross',\n",
       " 'SMA20Cross',\n",
       " 'SMA50Cross',\n",
       " 'SMA100Cross',\n",
       " 'SMA200Cross',\n",
       " 'UpDown10',\n",
       " 'UpDown15',\n",
       " 'UpDown50',\n",
       " 'Ticker_ACNFCOMF Index',\n",
       " 'Ticker_ADP CHNG Index',\n",
       " 'Ticker_AHE MOM% Index',\n",
       " 'Ticker_AHE YOY% Index',\n",
       " 'Ticker_AMSPPACE Index',\n",
       " 'Ticker_AWH TOTL Index',\n",
       " 'Ticker_BBRSCPYY Index',\n",
       " 'Ticker_BPGCGI Index',\n",
       " 'Ticker_CFNAI Index',\n",
       " 'Ticker_CGNOXAI% Index',\n",
       " 'Ticker_CGSHXAI% Index',\n",
       " 'Ticker_CHPMINDX Index',\n",
       " 'Ticker_CICRTOT Index',\n",
       " 'Ticker_CNSTTMOM Index',\n",
       " 'Ticker_COMFBTWR Index',\n",
       " 'Ticker_COMFCOMF Index',\n",
       " 'Ticker_CONCCONF Index',\n",
       " 'Ticker_CONCEXP Index',\n",
       " 'Ticker_CONCPSIT Index',\n",
       " 'Ticker_CONSCURR Index',\n",
       " 'Ticker_CONSEXP Index',\n",
       " 'Ticker_CONSP5MD Index',\n",
       " 'Ticker_CONSPXMD Index',\n",
       " 'Ticker_CONSSENT Index',\n",
       " 'Ticker_COSTNFR% Index',\n",
       " 'Ticker_CPI CHNG Index',\n",
       " 'Ticker_CPI XYOY Index',\n",
       " 'Ticker_CPI YOY Index',\n",
       " 'Ticker_CPTICHNG Index',\n",
       " 'Ticker_CPUPAXFE Index',\n",
       " 'Ticker_CPUPXCHG Index',\n",
       " 'Ticker_CPURNSA Index',\n",
       " 'Ticker_DFEDGBA Index',\n",
       " 'Ticker_DGNOCHNG Index',\n",
       " 'Ticker_DGNOXTCH Index',\n",
       " 'Ticker_DLQTDLQT Index',\n",
       " 'Ticker_DOTDLTMD Index',\n",
       " 'Ticker_DOTDY0MD Index',\n",
       " 'Ticker_DOTDY1MD Index',\n",
       " 'Ticker_DOTDY2MD Index',\n",
       " 'Ticker_DSERGBCC Index',\n",
       " 'Ticker_ECI SA% Index',\n",
       " 'Ticker_ECONGECC Index',\n",
       " 'Ticker_ECONUSIB Index',\n",
       " 'Ticker_EHSLMOM Index',\n",
       " 'Ticker_EHSLSL Index',\n",
       " 'Ticker_EMPRGBCI Index',\n",
       " 'Ticker_ETSLMOM Index',\n",
       " 'Ticker_ETSLTOTL Index',\n",
       " 'Ticker_EXP1CMOM Index',\n",
       " 'Ticker_EXP1CYOY Index',\n",
       " 'Ticker_FDDSSD Index',\n",
       " 'Ticker_FDEBTY Index',\n",
       " 'Ticker_FDIDFDMO Index',\n",
       " 'Ticker_FDIDSGMO Index',\n",
       " 'Ticker_FDIDSGUM Index',\n",
       " 'Ticker_FDIUFDYO Index',\n",
       " 'Ticker_FDIUSGUY Index',\n",
       " 'Ticker_FDIUSGYO Index',\n",
       " 'Ticker_FDTR Index',\n",
       " 'Ticker_FDTRFTRL Index',\n",
       " 'Ticker_FORLTOTL Index',\n",
       " 'Ticker_FRNTTNET Index',\n",
       " 'Ticker_FRNTTOTL Index',\n",
       " 'Ticker_GDP CQOQ Index',\n",
       " 'Ticker_GDP DCHG Index',\n",
       " 'Ticker_GDP PIQQ Index',\n",
       " 'Ticker_GDPCPCEC Index',\n",
       " 'Ticker_GDPCTOT% Index',\n",
       " 'Ticker_HOMEAFFR Index',\n",
       " 'Ticker_HPI PURQ Index',\n",
       " 'Ticker_HPI QOQ% Index',\n",
       " 'Ticker_HPIMMOM% Index',\n",
       " 'Ticker_HVRAHOME Index',\n",
       " 'Ticker_ICSHNATL Index',\n",
       " 'Ticker_IMP1CHNG Index',\n",
       " 'Ticker_IMP1XPM% Index',\n",
       " 'Ticker_IMP1YOY% Index',\n",
       " 'Ticker_INJCJC Index',\n",
       " 'Ticker_INJCSP Index',\n",
       " 'Ticker_IP CHNG Index',\n",
       " 'Ticker_IPMGCHNG Index',\n",
       " 'Ticker_IRRBIOER Index',\n",
       " 'Ticker_JOLTTOTL Index',\n",
       " 'Ticker_KCLSSACI Index',\n",
       " 'Ticker_KCSSMCOM Index',\n",
       " 'Ticker_LEI CHNG Index',\n",
       " 'Ticker_LHWANWPA Index',\n",
       " 'Ticker_LMCILMCC Index',\n",
       " 'Ticker_MAPMINDX Index',\n",
       " 'Ticker_MBAVCHNG Index',\n",
       " 'Ticker_MBRSWTW Index',\n",
       " 'Ticker_MBRXYOY Index',\n",
       " 'Ticker_MBRXYOYW Index',\n",
       " 'Ticker_MPMIUSCA Index',\n",
       " 'Ticker_MPMIUSMA Index',\n",
       " 'Ticker_MPMIUSSA Index',\n",
       " 'Ticker_MTIBCHNG Index',\n",
       " 'Ticker_MWINCHNG Index',\n",
       " 'Ticker_MWSLCHNG Index',\n",
       " 'Ticker_NABEEMPL Index',\n",
       " 'Ticker_NAPMEMPL Index',\n",
       " 'Ticker_NAPMNEMP Index',\n",
       " 'Ticker_NAPMNEWO Index',\n",
       " 'Ticker_NAPMNMAN Index',\n",
       " 'Ticker_NAPMNMI Index',\n",
       " 'Ticker_NAPMNNO Index',\n",
       " 'Ticker_NAPMNPRC Index',\n",
       " 'Ticker_NAPMPMI Index',\n",
       " 'Ticker_NAPMPRIC Index',\n",
       " 'Ticker_NFP CPYC Index',\n",
       " 'Ticker_NFP PCH Index',\n",
       " 'Ticker_NFP TCH Index',\n",
       " 'Ticker_NHCHATCH Index',\n",
       " 'Ticker_NHCHSTCH Index',\n",
       " 'Ticker_NHSLCHNG Index',\n",
       " 'Ticker_NHSLTOT Index',\n",
       " 'Ticker_NHSPATOT Index',\n",
       " 'Ticker_NHSPSTOT Index',\n",
       " 'Ticker_NYBLCNBA Index',\n",
       " 'Ticker_NYCNM1IR Index',\n",
       " 'Ticker_NYPMCURR Index',\n",
       " 'Ticker_OUTFGAF Index',\n",
       " 'Ticker_PCE CHNC Index',\n",
       " 'Ticker_PCE CMOM Index',\n",
       " 'Ticker_PCE CRCH Index',\n",
       " 'Ticker_PCE CYOY Index',\n",
       " 'Ticker_PCE DEFM Index',\n",
       " 'Ticker_PCE DEFY Index',\n",
       " 'Ticker_PHUCCHNG Index',\n",
       " 'Ticker_PHUCTOT Index',\n",
       " 'Ticker_PITLCHNG Index',\n",
       " 'Ticker_PNMARADI Index',\n",
       " 'Ticker_PPI CHNG Index',\n",
       " 'Ticker_PPI XYOY Index',\n",
       " 'Ticker_PPI YOY Index',\n",
       " 'Ticker_PRODNFR% Index',\n",
       " 'Ticker_PRUSTOT Index',\n",
       " 'Ticker_PXFECHNG Index',\n",
       " 'Ticker_RCHSINDX Index',\n",
       " 'Ticker_RCSSCLBC Index',\n",
       " 'Ticker_REALRAWE Index',\n",
       " 'Ticker_REALYRAE Index',\n",
       " 'Ticker_REALYRAW Index',\n",
       " 'Ticker_REDSMMOM Index',\n",
       " 'Ticker_RSRSTMOM Index',\n",
       " 'Ticker_RSTAMOM Index',\n",
       " 'Ticker_RSTAXAG% Index',\n",
       " 'Ticker_RSTAXAGM Index',\n",
       " 'Ticker_RSTAXMOM Index',\n",
       " 'Ticker_RTSDCHNG Index',\n",
       " 'Ticker_RTSDXCHG Index',\n",
       " 'Ticker_SAARDTOT Index',\n",
       " 'Ticker_SAARTOTL Index',\n",
       " 'Ticker_SBOITOTL Index',\n",
       " 'Ticker_SPCS20 Index',\n",
       " 'Ticker_SPCS20SM Index',\n",
       " 'Ticker_SPCS20Y% Index',\n",
       " 'Ticker_SPCSUSA Index',\n",
       " 'Ticker_SPCSUSAY Index',\n",
       " 'Ticker_SPCSUSQS Index',\n",
       " 'Ticker_TMNOCHNG Index',\n",
       " 'Ticker_TMNOXTM% Index',\n",
       " 'Ticker_TREFAMSP Index',\n",
       " 'Ticker_TREFPACE Index',\n",
       " 'Ticker_USCABAL Index',\n",
       " 'Ticker_USEMNCHG Index',\n",
       " 'Ticker_USHBMIDX Index',\n",
       " 'Ticker_USHETOT% Index',\n",
       " 'Ticker_USHEYOY Index',\n",
       " 'Ticker_USMMMNCH Index',\n",
       " 'Ticker_USPHTMOM Index',\n",
       " 'Ticker_USPHTYOY Index',\n",
       " 'Ticker_USTBTOT Index',\n",
       " 'Ticker_USTGTTCB Index',\n",
       " 'Ticker_USUDMAER Index',\n",
       " 'Ticker_USURTOT Index',\n",
       " 'Ticker_USWHMANS Index',\n",
       " 'Ticker_USWHTOT Index',\n",
       " 'Ticker_VNCCCMOM Index',\n",
       " 'Ticker_VNCCTOT Index',\n",
       " 'last_gdp_gr',\n",
       " 'last_vix']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af35ade",
   "metadata": {},
   "source": [
    "<h1>Final XGBoost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe8422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_returns = val_trade_df.groupby('DateTime').apply(\n",
      "C:\\Users\\Jop Brouwer\\AppData\\Local\\Temp\\ipykernel_27500\\13791412.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_returns = test_trade_df.groupby('DateTime').apply(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Cumulative Compounded Return: 162.17%\n",
      "\n",
      "Overall Test Accuracy : 48.53%\n",
      "Overall Precision     : 32.36%\n",
      "Overall Recall        : 33.30%\n",
      "Overall F1 Score      : 32.80%\n",
      "Overall ROC AUC       : 52.58%\n",
      "\n",
      "Average Fold Test Return : 0.01424%\n",
      "\n",
      "Standard Deviation of All Test Returns (Aggregated Daily): 0.26020%\n",
      "\n",
      "Minimum Return (Aggregated Daily): -0.97349%\n",
      "\n",
      "Optimal Horizon Counts:\n",
      "_double     15\n",
      "standard     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Set Position Counts:\n",
      "Neutral (0): 34\n",
      "Long (1): 7867\n",
      "Short (2): 6805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# --- Configuration ---\n",
    "total_cost = 2 * transaction_cost\n",
    "horizons = ['', '_half', '_double']\n",
    "\n",
    "# --- Data Prep ---\n",
    "df_ml = df_ml.dropna(subset=['Surprise']).sort_values('DateTime')\n",
    "min_date = df_ml['DateTime'].min()\n",
    "max_date = df_ml['DateTime'].max()\n",
    "\n",
    "# --- Calculate Initial 30% Training Period ---\n",
    "total_duration = max_date - min_date\n",
    "initial_train_duration = total_duration * 0.3\n",
    "train_end_date = min_date + initial_train_duration\n",
    "\n",
    "# --- Tracking containers ---\n",
    "results = []\n",
    "all_test_returns = []\n",
    "all_dates = []\n",
    "all_test_preds = []\n",
    "all_test_truths = []\n",
    "all_test_probas = []\n",
    "fold_mean_returns = []\n",
    "best_horizons_list = []\n",
    "\n",
    "def calculate_grouped_returns(df_group, horizon, stop_loss=None):\n",
    "    \"\"\"Calculate returns with position sizing and stop loss\"\"\"\n",
    "    active_trades = df_group[df_group['pred'] != 0]\n",
    "    if active_trades.empty:\n",
    "        return 0.0\n",
    "\n",
    "    longs = active_trades[active_trades['pred'] == 1]\n",
    "    shorts = active_trades[active_trades['pred'] == 2]\n",
    "\n",
    "    total_confidence = longs['proba'].sum() + shorts['proba'].sum()\n",
    "    if total_confidence == 0:\n",
    "        return 0.0\n",
    "\n",
    "    num_trades = len(longs) + len(shorts)\n",
    "    total_costs = total_cost * num_trades\n",
    "\n",
    "    long_returns = 0.0\n",
    "    short_returns = 0.0\n",
    "\n",
    "    # Process longs\n",
    "    if not longs.empty:\n",
    "        long_weights = longs['proba'] / total_confidence\n",
    "        for idx, row in longs.iterrows():\n",
    "            raw_return = row[f'Return{horizon}']\n",
    "            capped_raw = max(stop_loss, raw_return) if stop_loss is not None else raw_return\n",
    "            long_returns += capped_raw * long_weights.loc[idx]\n",
    "\n",
    "    # Process shorts\n",
    "    if not shorts.empty:\n",
    "        short_weights = shorts['proba'] / total_confidence\n",
    "        for idx, row in shorts.iterrows():\n",
    "            raw_return = -row[f'Return{horizon}']\n",
    "            capped_raw = max(stop_loss, raw_return) if stop_loss is not None else raw_return\n",
    "            short_returns += capped_raw * short_weights.loc[idx]\n",
    "\n",
    "    net_return = (long_returns + short_returns) - total_costs\n",
    "    return net_return\n",
    "\n",
    "# --- Main Loop ---\n",
    "while True:\n",
    "    val_start_date = train_end_date + pd.DateOffset(days=1)\n",
    "    val_end_date = val_start_date + pd.DateOffset(years=1)\n",
    "    test_start_date = val_end_date + pd.DateOffset(days=1)\n",
    "    test_end_date = test_start_date + pd.DateOffset(years=1)\n",
    "\n",
    "    if val_end_date > max_date or test_end_date > max_date:\n",
    "        break\n",
    "\n",
    "    train_mask = df_ml['DateTime'] <= train_end_date\n",
    "    val_mask = (df_ml['DateTime'] >= val_start_date) & (df_ml['DateTime'] <= val_end_date)\n",
    "    test_mask = (df_ml['DateTime'] >= test_start_date) & (df_ml['DateTime'] <= test_end_date)\n",
    "\n",
    "    train_data = df_ml[train_mask]\n",
    "    val_data = df_ml[val_mask]\n",
    "    test_data = df_ml[test_mask]\n",
    "\n",
    "    if val_data.empty or test_data.empty:\n",
    "        print(f\"Skipping period {val_start_date.date()} to {test_end_date.date()} (no data)\")\n",
    "        train_end_date += pd.DateOffset(years=1)\n",
    "        continue\n",
    "\n",
    "    # --- Horizon Optimization ---\n",
    "    best_horizon, best_model, best_stop_loss = None, None, None\n",
    "    best_val_return = -np.inf\n",
    "\n",
    "    for horizon in horizons:\n",
    "        # Feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(train_data[feature_cols])\n",
    "        X_val = scaler.transform(val_data[feature_cols])\n",
    "        y_train = train_data[f'Profit{horizon}']\n",
    "        y_val = val_data[f'Profit{horizon}']\n",
    "\n",
    "        # Train model\n",
    "        model = xgb.XGBClassifier(\n",
    "            num_class=3,\n",
    "            n_estimators=60,\n",
    "            max_depth=7,\n",
    "            random_state=42,\n",
    "            seed=42\n",
    "        )\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "        # Calculate training stop loss\n",
    "        train_preds = model.predict(X_train)\n",
    "        train_trade_df = pd.DataFrame({\n",
    "            'DateTime': train_data['DateTime'],\n",
    "            'pred': train_preds,\n",
    "            'proba': [p[pred] for pred, p in zip(train_preds, model.predict_proba(X_train))],\n",
    "            f'Return{horizon}': train_data[f'Return{horizon}']\n",
    "        })\n",
    "\n",
    "        individual_train_returns = []\n",
    "        for _, row in train_trade_df.iterrows():\n",
    "            if row['pred'] == 1:\n",
    "                raw = row[f'Return{horizon}']\n",
    "            elif row['pred'] == 2:\n",
    "                raw = -row[f'Return{horizon}']\n",
    "            else:\n",
    "                continue\n",
    "            individual_train_returns.append(raw)\n",
    "\n",
    "        stop_loss_train = np.percentile(individual_train_returns, 5) if individual_train_returns else None\n",
    "\n",
    "        # Calculate validation stop loss (for test set)\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_probas = model.predict_proba(X_val)\n",
    "        val_trade_df = pd.DataFrame({\n",
    "            'DateTime': val_data['DateTime'],\n",
    "            'pred': val_preds,\n",
    "            'proba': [p[pred] for pred, p in zip(val_preds, val_probas)],\n",
    "            f'Return{horizon}': val_data[f'Return{horizon}']\n",
    "        })\n",
    "\n",
    "        individual_val_returns = []\n",
    "        for _, row in val_trade_df.iterrows():\n",
    "            if row['pred'] == 1:\n",
    "                raw = row[f'Return{horizon}']\n",
    "            elif row['pred'] == 2:\n",
    "                raw = -row[f'Return{horizon}']\n",
    "            else:\n",
    "                continue\n",
    "            individual_val_returns.append(raw)\n",
    "\n",
    "        stop_loss_val = np.percentile(individual_val_returns, 5) if individual_val_returns else None\n",
    "\n",
    "        # Validate using TRAINING stop loss\n",
    "        val_returns = val_trade_df.groupby('DateTime').apply(\n",
    "            lambda x: calculate_grouped_returns(x, horizon, stop_loss_train)\n",
    "        ).values\n",
    "\n",
    "        total_val_return = (1 + val_returns).prod() - 1\n",
    "\n",
    "        if total_val_return > best_val_return:\n",
    "            best_val_return = total_val_return\n",
    "            best_horizon = horizon\n",
    "            best_model = model\n",
    "            best_stop_loss = stop_loss_val  # Save validation stop loss for test\n",
    "\n",
    "    # --- Test Best Model ---\n",
    "    if best_model and best_stop_loss is not None:\n",
    "        X_test = scaler.transform(test_data[feature_cols])\n",
    "        test_preds = best_model.predict(X_test)\n",
    "        test_probas = best_model.predict_proba(X_test)\n",
    "        y_test = test_data[f'Profit{best_horizon}'].values\n",
    "\n",
    "        test_trade_df = pd.DataFrame({\n",
    "            'DateTime': test_data['DateTime'],\n",
    "            'pred': test_preds,\n",
    "            'proba': [p[pred] for pred, p in zip(test_preds, test_probas)],\n",
    "            f'Return{best_horizon}': test_data[f'Return{best_horizon}']\n",
    "        })\n",
    "\n",
    "        grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
    "            lambda x: calculate_grouped_returns(x, best_horizon, best_stop_loss)\n",
    "        ).values\n",
    "\n",
    "        all_test_returns.extend(grouped_returns)\n",
    "        all_dates.extend(test_trade_df['DateTime'].unique().tolist())\n",
    "        all_test_preds.extend(test_preds)\n",
    "        all_test_truths.extend(y_test)\n",
    "        all_test_probas.append(test_probas)\n",
    "        fold_mean_returns.append(np.mean(grouped_returns))\n",
    "        best_horizons_list.append(best_horizon or 'standard')\n",
    "\n",
    "    train_end_date += pd.DateOffset(years=1)\n",
    "\n",
    "# --- Results ---\n",
    "if all_test_returns:\n",
    "    cumulative_returns = (1 + np.array(all_test_returns)).cumprod() - 1\n",
    "    std_dev_individual = np.std(all_test_returns) * 100\n",
    "    min_return = np.nanmin(all_test_returns) * 100 if all_test_returns else 0.0\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(all_dates, cumulative_returns * 100)\n",
    "    plt.title('Cumulative Returns (DateTime-Based Rolling Windows)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Return (%)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Final Cumulative Compounded Return: {cumulative_returns[-1]*100:.2f}%\")\n",
    "    print(f\"\\nOverall Test Accuracy : {accuracy_score(all_test_truths, all_test_preds)*100:.2f}%\")\n",
    "    print(f\"Overall Precision     : {precision_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall Recall        : {recall_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall F1 Score      : {f1_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall ROC AUC       : {roc_auc_score(all_test_truths, np.vstack(all_test_probas), multi_class='ovo', average='macro')*100:.2f}%\")\n",
    "    print(f\"\\nAverage Fold Test Return : {np.mean(fold_mean_returns)*100:.5f}%\")\n",
    "    print(f\"\\nStandard Deviation of All Test Returns (Aggregated Daily): {std_dev_individual:.5f}%\")\n",
    "    print(f\"\\nMinimum Return (Aggregated Daily): {min_return:.5f}%\")\n",
    "    print(\"\\nOptimal Horizon Counts:\")\n",
    "    print(pd.Series(best_horizons_list).value_counts())\n",
    "    print(\"\\nTest Set Position Counts:\")\n",
    "    counts = pd.Series(all_test_preds).value_counts().sort_index()\n",
    "    print(f\"Neutral (0): {counts.get(0, 0)}\")\n",
    "    print(f\"Long (1): {counts.get(1, 0)}\")\n",
    "    print(f\"Short (2): {counts.get(2, 0)}\")\n",
    "\n",
    "else:\n",
    "    print(\"No valid test periods found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbabf92f",
   "metadata": {},
   "source": [
    "Last results = 162%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "                    Pred Neutral (0)  Pred Long (1)  Pred Short (2)\n",
      "Actual Neutral (0)                 0            200             244\n",
      "Actual Long (1)                   12           3929            3353\n",
      "Actual Short (2)                  22           3738            3208\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Neutral (0)       0.00      0.00      0.00       444\n",
      "    Long (1)       0.50      0.54      0.52      7294\n",
      "   Short (2)       0.47      0.46      0.47      6968\n",
      "\n",
      "    accuracy                           0.49     14706\n",
      "   macro avg       0.32      0.33      0.33     14706\n",
      "weighted avg       0.47      0.49      0.48     14706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Add this after your existing print statements\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_test_truths, all_test_preds)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                    index=['Actual Neutral (0)', 'Actual Long (1)', 'Actual Short (2)'],\n",
    "                    columns=['Pred Neutral (0)', 'Pred Long (1)', 'Pred Short (2)'])\n",
    "print(cm_df)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_test_truths, all_test_preds,\n",
    "                           target_names=['Neutral (0)', 'Long (1)', 'Short (2)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e1424",
   "metadata": {},
   "source": [
    "<h1>Final Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dbde45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m    122\u001b[39m model = RandomForestClassifier(\n\u001b[32m    123\u001b[39m     n_estimators=\u001b[32m100\u001b[39m,\n\u001b[32m    124\u001b[39m     criterion=\u001b[33m'\u001b[39m\u001b[33mgini\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    125\u001b[39m     min_samples_leaf=\u001b[32m4\u001b[39m,\n\u001b[32m    126\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m    127\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Get class probabilities\u001b[39;00m\n\u001b[32m    131\u001b[39m train_preds = model.predict(X_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    349\u001b[39m     sample_weight = _check_sample_weight(sample_weight, X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, **check_params)\u001b[39m\n\u001b[32m    582\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m    583\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m     out = X, y\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1101\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1103\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1122\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1124\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    915\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    916\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    917\u001b[39m             % (array.ndim, estimator_name)\n\u001b[32m    918\u001b[39m         )\n\u001b[32m    920\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples > \u001b[32m0\u001b[39m:\n\u001b[32m    929\u001b[39m     n_samples = _num_samples(array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    146\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    147\u001b[39m     msg_err += (\n\u001b[32m    148\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    149\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# --- Configuration ---\n",
    "total_cost = 2 * transaction_cost\n",
    "horizons = ['', '_half', '_double']\n",
    "\n",
    "# --- Data Prep ---\n",
    "df_ml = df_ml.dropna(subset=['Surprise']).sort_values('DateTime')\n",
    "min_date = df_ml['DateTime'].min()\n",
    "max_date = df_ml['DateTime'].max()\n",
    "\n",
    "# --- Calculate Initial 30% Training Period ---\n",
    "total_duration = max_date - min_date\n",
    "initial_train_duration = total_duration * 0.3\n",
    "train_end_date = min_date + initial_train_duration\n",
    "\n",
    "# --- Tracking containers ---\n",
    "results = []\n",
    "all_test_returns = []\n",
    "all_dates = []\n",
    "all_test_preds = []\n",
    "all_test_truths = []\n",
    "all_test_probas = []\n",
    "fold_mean_returns = []\n",
    "best_horizons_list = []\n",
    "\n",
    "def calculate_grouped_returns(df_group, horizon, stop_loss=None):\n",
    "    \"\"\"Calculate returns with position sizing and stop loss\"\"\"\n",
    "    active_trades = df_group[df_group['pred'] != 0]\n",
    "    if active_trades.empty:\n",
    "        return 0.0\n",
    "\n",
    "    # Create copies with reset index\n",
    "    longs = active_trades[active_trades['pred'] == 1].copy().reset_index(drop=True)\n",
    "    shorts = active_trades[active_trades['pred'] == 2].copy().reset_index(drop=True)\n",
    "\n",
    "    total_confidence = longs['proba'].sum() + shorts['proba'].sum()\n",
    "    if total_confidence == 0:\n",
    "        return 0.0\n",
    "\n",
    "    num_trades = len(longs) + len(shorts)\n",
    "    total_costs = total_cost * num_trades\n",
    "\n",
    "    long_returns = 0.0\n",
    "    short_returns = 0.0\n",
    "\n",
    "    # Process longs with reset index\n",
    "    if not longs.empty:\n",
    "        long_weights = longs['proba'] / total_confidence\n",
    "        for idx in longs.index:\n",
    "            raw_return = longs.loc[idx, f'Return{horizon}']\n",
    "            capped_raw = max(stop_loss, raw_return) if stop_loss is not None else raw_return\n",
    "            long_returns += capped_raw * long_weights.loc[idx]\n",
    "\n",
    "    # Process shorts with reset index\n",
    "    if not shorts.empty:\n",
    "        short_weights = shorts['proba'] / total_confidence\n",
    "        for idx in shorts.index:\n",
    "            raw_return = -shorts.loc[idx, f'Return{horizon}']\n",
    "            capped_raw = max(stop_loss, raw_return) if stop_loss is not None else raw_return\n",
    "            short_returns += capped_raw * short_weights.loc[idx]\n",
    "\n",
    "    net_return = (long_returns + short_returns) - total_costs\n",
    "    return net_return\n",
    "\n",
    "# --- Main Loop ---\n",
    "while True:\n",
    "    val_start_date = train_end_date + pd.DateOffset(days=1)\n",
    "    val_end_date = val_start_date + pd.DateOffset(years=1)\n",
    "    test_start_date = val_end_date + pd.DateOffset(days=1)\n",
    "    test_end_date = test_start_date + pd.DateOffset(years=1)\n",
    "\n",
    "    if val_end_date > max_date or test_end_date > max_date:\n",
    "        break\n",
    "\n",
    "    train_mask = df_ml['DateTime'] <= train_end_date\n",
    "    val_mask = (df_ml['DateTime'] >= val_start_date) & (df_ml['DateTime'] <= val_end_date)\n",
    "    test_mask = (df_ml['DateTime'] >= test_start_date) & (df_ml['DateTime'] <= test_end_date)\n",
    "\n",
    "    train_data = df_ml[train_mask]\n",
    "    val_data = df_ml[val_mask]\n",
    "    test_data = df_ml[test_mask]\n",
    "\n",
    "    if val_data.empty or test_data.empty:\n",
    "        print(f\"Skipping period {val_start_date.date()} to {test_end_date.date()} (no data)\")\n",
    "        train_end_date += pd.DateOffset(years=1)\n",
    "        continue\n",
    "\n",
    "    # --- Horizon Optimization ---\n",
    "    best_horizon, best_model, best_stop_loss = None, None, None\n",
    "    best_val_return = -np.inf\n",
    "\n",
    "    for horizon in horizons:\n",
    "        # Feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(train_data[feature_cols])\n",
    "        X_val = scaler.transform(val_data[feature_cols])\n",
    "        y_train = train_data[f'Profit{horizon}']\n",
    "        y_val = val_data[f'Profit{horizon}']\n",
    "\n",
    "        # Train model\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            criterion='gini',\n",
    "            min_samples_leaf=4,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Get class probabilities\n",
    "        train_preds = model.predict(X_train)\n",
    "        train_probas = model.predict_proba(X_train)\n",
    "        class_map = {cls: idx for idx, cls in enumerate(model.classes_)}\n",
    "\n",
    "        # Training stop loss calculation\n",
    "        train_trade_df = pd.DataFrame({\n",
    "            'DateTime': train_data['DateTime'],\n",
    "            'pred': train_preds,\n",
    "            'proba': [proba[class_map[pred]] for pred, proba in zip(train_preds, train_probas)],\n",
    "            f'Return{horizon}': train_data[f'Return{horizon}']\n",
    "        })\n",
    "\n",
    "        train_raw_returns = []\n",
    "        for _, row in train_trade_df.iterrows():\n",
    "            if row['pred'] == 1:\n",
    "                train_raw_returns.append(row[f'Return{horizon}'])\n",
    "            elif row['pred'] == 2:\n",
    "                train_raw_returns.append(-row[f'Return{horizon}'])\n",
    "        stop_loss_train = np.percentile(train_raw_returns, 5) if train_raw_returns else None\n",
    "\n",
    "        # Validation predictions\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_probas = model.predict_proba(X_val)\n",
    "        val_trade_df = pd.DataFrame({\n",
    "            'DateTime': val_data['DateTime'],\n",
    "            'pred': val_preds,\n",
    "            'proba': [proba[class_map[pred]] for pred, proba in zip(val_preds, val_probas)],\n",
    "            f'Return{horizon}': val_data[f'Return{horizon}']\n",
    "        })\n",
    "\n",
    "        # Validation stop loss calculation (for test set)\n",
    "        val_raw_returns = []\n",
    "        for _, row in val_trade_df.iterrows():\n",
    "            if row['pred'] == 1:\n",
    "                val_raw_returns.append(row[f'Return{horizon}'])\n",
    "            elif row['pred'] == 2:\n",
    "                val_raw_returns.append(-row[f'Return{horizon}'])\n",
    "        stop_loss_val = np.percentile(val_raw_returns, 5) if val_raw_returns else None\n",
    "\n",
    "        # Validate using training stop loss\n",
    "        val_returns = val_trade_df.groupby('DateTime').apply(\n",
    "            lambda x: calculate_grouped_returns(x, horizon, stop_loss_train)\n",
    "        ).values\n",
    "\n",
    "        total_val_return = (1 + val_returns).prod() - 1\n",
    "\n",
    "        if total_val_return > best_val_return:\n",
    "            best_val_return = total_val_return\n",
    "            best_horizon = horizon\n",
    "            best_model = model\n",
    "            best_stop_loss = stop_loss_val\n",
    "\n",
    "    # --- Test Best Model ---\n",
    "    if best_model and best_stop_loss is not None:\n",
    "        X_test = scaler.transform(test_data[feature_cols])\n",
    "        test_preds = best_model.predict(X_test)\n",
    "        test_probas = best_model.predict_proba(X_test)\n",
    "        y_test = test_data[f'Profit{best_horizon}'].values\n",
    "\n",
    "        class_map = {cls: idx for idx, cls in enumerate(best_model.classes_)}\n",
    "        test_trade_df = pd.DataFrame({\n",
    "            'DateTime': test_data['DateTime'],\n",
    "            'pred': test_preds,\n",
    "            'proba': [proba[class_map[pred]] for pred, proba in zip(test_preds, test_probas)],\n",
    "            f'Return{best_horizon}': test_data[f'Return{best_horizon}']\n",
    "        })\n",
    "\n",
    "        grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
    "            lambda x: calculate_grouped_returns(x, best_horizon, best_stop_loss)\n",
    "        ).values\n",
    "\n",
    "        all_test_returns.extend(grouped_returns)\n",
    "        all_dates.extend(test_trade_df['DateTime'].unique().tolist())\n",
    "        all_test_preds.extend(test_preds)\n",
    "        all_test_truths.extend(y_test)\n",
    "        all_test_probas.append(test_probas)\n",
    "        fold_mean_returns.append(np.mean(grouped_returns))\n",
    "        best_horizons_list.append(best_horizon or 'standard')\n",
    "\n",
    "    train_end_date += pd.DateOffset(years=1)\n",
    "\n",
    "# --- Results ---\n",
    "if all_test_returns:\n",
    "    cumulative_returns = (1 + np.array(all_test_returns)).cumprod() - 1\n",
    "    std_dev_individual = np.std(all_test_returns) * 100\n",
    "    min_return = np.nanmin(all_test_returns) * 100 if all_test_returns else 0.0\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(all_dates, cumulative_returns * 100)\n",
    "    plt.title('Cumulative Returns (Random Forest with Stop Loss)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Return (%)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Final Cumulative Compounded Return: {cumulative_returns[-1]*100:.2f}%\")\n",
    "    print(f\"\\nOverall Test Accuracy : {accuracy_score(all_test_truths, all_test_preds)*100:.2f}%\")\n",
    "    print(f\"Overall Precision     : {precision_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall Recall        : {recall_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall F1 Score      : {f1_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall ROC AUC       : {roc_auc_score(all_test_truths, np.vstack(all_test_probas), multi_class='ovo', average='macro')*100:.2f}%\")\n",
    "    print(f\"\\nAverage Fold Test Return : {np.mean(fold_mean_returns)*100:.5f}%\")\n",
    "    print(f\"\\nStandard Deviation of All Test Returns (Aggregated Daily): {std_dev_individual:.5f}%\")\n",
    "    print(f\"\\nMinimum Return (Aggregated Daily): {min_return:.5f}%\")\n",
    "    print(\"\\nOptimal Horizon Counts:\")\n",
    "    print(pd.Series(best_horizons_list).value_counts())\n",
    "    print(\"\\nTest Set Position Counts:\")\n",
    "    counts = pd.Series(all_test_preds).value_counts().sort_index()\n",
    "    print(f\"Neutral (0): {counts.get(0, 0)}\")\n",
    "    print(f\"Long (1): {counts.get(1, 0)}\")\n",
    "    print(f\"Short (2): {counts.get(2, 0)}\")\n",
    "\n",
    "else:\n",
    "    print(\"No valid test periods found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39eed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "                    Pred Neutral (0)  Pred Long (1)  Pred Short (2)\n",
      "Actual Neutral (0)                 0            238             204\n",
      "Actual Long (1)                    0           4057            3262\n",
      "Actual Short (2)                   0           3794            3151\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Neutral (0)       0.00      0.00      0.00       442\n",
      "    Long (1)       0.50      0.55      0.53      7319\n",
      "   Short (2)       0.48      0.45      0.46      6945\n",
      "\n",
      "    accuracy                           0.49     14706\n",
      "   macro avg       0.33      0.34      0.33     14706\n",
      "weighted avg       0.47      0.49      0.48     14706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# RF confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Add this after your existing print statements\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_test_truths, all_test_preds)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                    index=['Actual Neutral (0)', 'Actual Long (1)', 'Actual Short (2)'],\n",
    "                    columns=['Pred Neutral (0)', 'Pred Long (1)', 'Pred Short (2)'])\n",
    "print(cm_df)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_test_truths, all_test_preds,\n",
    "                           target_names=['Neutral (0)', 'Long (1)', 'Short (2)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727e5a0",
   "metadata": {},
   "source": [
    "<h1>Final Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd364abf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[114]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Train Logistic Regression\u001b[39;00m\n\u001b[32m    117\u001b[39m model = LogisticRegression(\n\u001b[32m    118\u001b[39m     multi_class=\u001b[33m'\u001b[39m\u001b[33mmultinomial\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    119\u001b[39m     solver=\u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    120\u001b[39m     max_iter=\u001b[32m100\u001b[39m,\n\u001b[32m    121\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m    122\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Training stop loss calculation\u001b[39;00m\n\u001b[32m    126\u001b[39m train_preds = model.predict(X_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1222\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1219\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1220\u001b[39m     _dtype = [np.float64, np.float32]\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mliblinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaga\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1231\u001b[39m check_classification_targets(y)\n\u001b[32m   1232\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = np.unique(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2959\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2960\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2961\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2962\u001b[39m     out = X, y\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1365\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1366\u001b[39m     )\n\u001b[32m   1368\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1389\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jop Brouwer\\Documents\\GitHub\\Data-Science-Seminar-Group-Project-5\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---\n",
    "total_cost = 2 * transaction_cost  # Total cost per trade (entry + exit)\n",
    "horizons = ['', '_half', '_double']\n",
    "\n",
    "# --- Data Prep ---\n",
    "df_ml = df_ml.dropna(subset=['Surprise']).sort_values('DateTime')\n",
    "min_date = df_ml['DateTime'].min()\n",
    "max_date = df_ml['DateTime'].max()\n",
    "\n",
    "# --- Calculate Initial 30% Training Period ---\n",
    "total_duration = max_date - min_date\n",
    "initial_train_duration = total_duration * 0.3\n",
    "train_end_date = min_date + initial_train_duration\n",
    "\n",
    "# --- Tracking containers ---\n",
    "all_test_returns = []\n",
    "all_dates = []\n",
    "all_test_preds = []\n",
    "all_test_truths = []\n",
    "all_test_probas = []\n",
    "fold_mean_returns = []\n",
    "best_horizons_list = []\n",
    "\n",
    "def calculate_grouped_returns(df_group, horizon, stop_loss=None):\n",
    "    \"\"\"Calculate returns with position sizing and stop loss\"\"\"\n",
    "    active_trades = df_group[df_group['pred'] != 0]\n",
    "    if active_trades.empty:\n",
    "        return 0.0\n",
    "\n",
    "    # Create copies with reset index\n",
    "    longs = active_trades[active_trades['pred'] == 1].copy().reset_index(drop=True)\n",
    "    shorts = active_trades[active_trades['pred'] == 2].copy().reset_index(drop=True)\n",
    "\n",
    "    total_confidence = longs['proba'].sum() + shorts['proba'].sum()\n",
    "    if total_confidence == 0:\n",
    "        return 0.0\n",
    "\n",
    "    num_trades = len(longs) + len(shorts)\n",
    "    total_costs = total_cost * num_trades\n",
    "\n",
    "    long_returns = 0.0\n",
    "    short_returns = 0.0\n",
    "\n",
    "    # Process longs with capping\n",
    "    if not longs.empty:\n",
    "        long_weights = longs['proba'] / total_confidence\n",
    "        for idx in longs.index:\n",
    "            raw_return = longs.loc[idx, f'Return{horizon}']\n",
    "            capped_raw = max(stop_loss, raw_return) if stop_loss is not None else raw_return\n",
    "            long_returns += capped_raw * long_weights.loc[idx]\n",
    "\n",
    "    # Process shorts with capping\n",
    "    if not shorts.empty:\n",
    "        short_weights = shorts['proba'] / total_confidence\n",
    "        for idx in shorts.index:\n",
    "            raw_return = -shorts.loc[idx, f'Return{horizon}']\n",
    "            capped_raw = max(stop_loss, raw_return) if stop_loss is not None else raw_return\n",
    "            short_returns += capped_raw * short_weights.loc[idx]\n",
    "\n",
    "    net_return = (long_returns + short_returns) - total_costs\n",
    "    return net_return\n",
    "\n",
    "# --- Main Loop ---\n",
    "while True:\n",
    "    val_start_date = train_end_date + pd.DateOffset(days=1)\n",
    "    val_end_date = val_start_date + pd.DateOffset(years=1)\n",
    "    test_start_date = val_end_date + pd.DateOffset(days=1)\n",
    "    test_end_date = test_start_date + pd.DateOffset(years=1)\n",
    "\n",
    "    if val_end_date > max_date or test_end_date > max_date:\n",
    "        break\n",
    "\n",
    "    train_mask = df_ml['DateTime'] <= train_end_date\n",
    "    val_mask = (df_ml['DateTime'] >= val_start_date) & (df_ml['DateTime'] <= val_end_date)\n",
    "    test_mask = (df_ml['DateTime'] >= test_start_date) & (df_ml['DateTime'] <= test_end_date)\n",
    "\n",
    "    train_data = df_ml[train_mask]\n",
    "    val_data = df_ml[val_mask]\n",
    "    test_data = df_ml[test_mask]\n",
    "\n",
    "    if val_data.empty or test_data.empty:\n",
    "        print(f\"Skipping period {val_start_date.date()} to {test_end_date.date()} (no data)\")\n",
    "        train_end_date += pd.DateOffset(years=1)\n",
    "        continue\n",
    "\n",
    "    # --- Horizon Optimization ---\n",
    "    best_horizon, best_model, best_stop_loss = None, None, None\n",
    "    best_val_return = -np.inf\n",
    "\n",
    "    for horizon in horizons:\n",
    "        # Feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(train_data[feature_cols])\n",
    "        X_val = scaler.transform(val_data[feature_cols])\n",
    "        y_train = train_data[f'Profit{horizon}']\n",
    "        y_val = val_data[f'Profit{horizon}']\n",
    "\n",
    "        # Train Logistic Regression\n",
    "        model = LogisticRegression(\n",
    "            multi_class='multinomial',\n",
    "            solver='saga',\n",
    "            max_iter=100,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Training stop loss calculation\n",
    "        train_preds = model.predict(X_train)\n",
    "        train_probas = model.predict_proba(X_train)\n",
    "        class_map = {cls: idx for idx, cls in enumerate(model.classes_)}\n",
    "\n",
    "        train_trade_df = pd.DataFrame({\n",
    "            'DateTime': train_data['DateTime'],\n",
    "            'pred': train_preds,\n",
    "            'proba': [proba[class_map[pred]] for pred, proba in zip(train_preds, train_probas)],\n",
    "            f'Return{horizon}': train_data[f'Return{horizon}']\n",
    "        })\n",
    "\n",
    "        train_raw_returns = []\n",
    "        for _, row in train_trade_df.iterrows():\n",
    "            if row['pred'] == 1:\n",
    "                train_raw_returns.append(row[f'Return{horizon}'])\n",
    "            elif row['pred'] == 2:\n",
    "                train_raw_returns.append(-row[f'Return{horizon}'])\n",
    "        stop_loss_train = np.percentile(train_raw_returns, 5) if train_raw_returns else None\n",
    "\n",
    "        # Validation predictions and stop loss\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_probas = model.predict_proba(X_val)\n",
    "        val_trade_df = pd.DataFrame({\n",
    "            'DateTime': val_data['DateTime'],\n",
    "            'pred': val_preds,\n",
    "            'proba': [proba[class_map[pred]] for pred, proba in zip(val_preds, val_probas)],\n",
    "            f'Return{horizon}': val_data[f'Return{horizon}']\n",
    "        })\n",
    "\n",
    "        val_raw_returns = []\n",
    "        for _, row in val_trade_df.iterrows():\n",
    "            if row['pred'] == 1:\n",
    "                val_raw_returns.append(row[f'Return{horizon}'])\n",
    "            elif row['pred'] == 2:\n",
    "                val_raw_returns.append(-row[f'Return{horizon}'])\n",
    "        stop_loss_val = np.percentile(val_raw_returns, 5) if val_raw_returns else None\n",
    "\n",
    "        # Validate using training stop loss\n",
    "        val_returns = val_trade_df.groupby('DateTime').apply(\n",
    "            lambda x: calculate_grouped_returns(x, horizon, stop_loss_train)\n",
    "        ).values\n",
    "\n",
    "        total_val_return = (1 + val_returns).prod() - 1\n",
    "\n",
    "        if total_val_return > best_val_return:\n",
    "            best_val_return = total_val_return\n",
    "            best_horizon = horizon\n",
    "            best_model = model\n",
    "            best_stop_loss = stop_loss_val\n",
    "\n",
    "    # --- Test Best Model ---\n",
    "    if best_model and best_stop_loss is not None:\n",
    "        X_test = scaler.transform(test_data[feature_cols])\n",
    "        test_preds = best_model.predict(X_test)\n",
    "        test_probas = best_model.predict_proba(X_test)\n",
    "        y_test = test_data[f'Profit{best_horizon}'].values\n",
    "\n",
    "        class_map = {cls: idx for idx, cls in enumerate(best_model.classes_)}\n",
    "        test_trade_df = pd.DataFrame({\n",
    "            'DateTime': test_data['DateTime'],\n",
    "            'pred': test_preds,\n",
    "            'proba': [proba[class_map[pred]] for pred, proba in zip(test_preds, test_probas)],\n",
    "            f'Return{best_horizon}': test_data[f'Return{best_horizon}']\n",
    "        })\n",
    "\n",
    "        grouped_returns = test_trade_df.groupby('DateTime').apply(\n",
    "            lambda x: calculate_grouped_returns(x, best_horizon, best_stop_loss)\n",
    "        ).values\n",
    "\n",
    "        all_test_returns.extend(grouped_returns)\n",
    "        all_dates.extend(test_trade_df['DateTime'].unique().tolist())\n",
    "        all_test_preds.extend(test_preds)\n",
    "        all_test_truths.extend(y_test)\n",
    "        all_test_probas.append(test_probas)\n",
    "        fold_mean_returns.append(np.mean(grouped_returns))\n",
    "        best_horizons_list.append(best_horizon or 'standard')\n",
    "\n",
    "    train_end_date += pd.DateOffset(years=1)\n",
    "\n",
    "# --- Results ---\n",
    "if all_test_returns:\n",
    "    cumulative_returns = (1 + np.array(all_test_returns)).cumprod() - 1\n",
    "    std_dev_individual = np.std(all_test_returns) * 100\n",
    "    min_return = np.nanmin(all_test_returns) * 100 if all_test_returns else 0.0\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(all_dates, cumulative_returns * 100)\n",
    "    plt.title('Cumulative Returns (Logistic Regression with Stop Loss)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Return (%)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Final Cumulative Compounded Return: {cumulative_returns[-1]*100:.2f}%\")\n",
    "    print(f\"\\nOverall Test Accuracy : {accuracy_score(all_test_truths, all_test_preds)*100:.2f}%\")\n",
    "    print(f\"Overall Precision     : {precision_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall Recall        : {recall_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall F1 Score      : {f1_score(all_test_truths, all_test_preds, average='macro', zero_division=0)*100:.2f}%\")\n",
    "    print(f\"Overall ROC AUC       : {roc_auc_score(all_test_truths, np.vstack(all_test_probas), multi_class='ovo', average='macro')*100:.2f}%\")\n",
    "    print(f\"\\nAverage Fold Test Return : {np.mean(fold_mean_returns)*100:.5f}%\")\n",
    "    print(f\"\\nStandard Deviation of All Test Returns (Aggregated Daily): {std_dev_individual:.5f}%\")\n",
    "    print(f\"\\nMinimum Return (Aggregated Daily): {min_return:.5f}%\")\n",
    "    print(\"\\nOptimal Horizon Counts:\")\n",
    "    print(pd.Series(best_horizons_list).value_counts())\n",
    "    print(\"\\nTest Set Position Counts:\")\n",
    "    counts = pd.Series(all_test_preds).value_counts().sort_index()\n",
    "    print(f\"Neutral (0): {counts.get(0, 0)}\")\n",
    "    print(f\"Long (1): {counts.get(1, 0)}\")\n",
    "    print(f\"Short (2): {counts.get(2, 0)}\")\n",
    "\n",
    "else:\n",
    "    print(\"No valid test periods found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4812d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Add this after your existing print statements\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_test_truths, all_test_preds)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                    index=['Actual Neutral (0)', 'Actual Long (1)', 'Actual Short (2)'],\n",
    "                    columns=['Pred Neutral (0)', 'Pred Long (1)', 'Pred Short (2)'])\n",
    "print(cm_df)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_test_truths, all_test_preds,\n",
    "                           target_names=['Neutral (0)', 'Long (1)', 'Short (2)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
